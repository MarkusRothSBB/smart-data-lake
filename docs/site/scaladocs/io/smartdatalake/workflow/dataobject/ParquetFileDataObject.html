<!DOCTYPE html >
<html>
        <head>
          <meta http-equiv="X-UA-Compatible" content="IE=edge" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
          <title>sdl-core 2.0.4 API  - io.smartdatalake.workflow.dataobject.ParquetFileDataObject</title>
          <meta name="description" content="sdl - core 2.0.4 API - io.smartdatalake.workflow.dataobject.ParquetFileDataObject" />
          <meta name="keywords" content="sdl core 2.0.4 API io.smartdatalake.workflow.dataobject.ParquetFileDataObject" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      
      <link href="../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../lib/jquery.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.panzoom.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.mousewheel.min.js"></script>
      <script type="text/javascript" src="../../../../lib/index.js"></script>
      <script type="text/javascript" src="../../../../index.js"></script>
      <script type="text/javascript" src="../../../../lib/scheduler.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      
      <script type="text/javascript">
        /* this variable can be used by the JS to determine the path to the root document */
        var toRoot = '../../../../';
      </script>
    
        </head>
        <body>
      <div id="search">
        <span id="doc-title">sdl-core 2.0.4 API<span id="doc-version"></span></span>
        <span class="close-results"><span class="left">&lt;</span> Back</span>
        <div id="textfilter">
          <span class="input">
            <input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/" />
            <i class="clear material-icons"></i>
            <i id="search-icon" class="material-icons"></i>
          </span>
        </div>
    </div>
      <div id="search-results">
        <div id="search-progress">
          <div id="progress-fill"></div>
        </div>
        <div id="results-content">
          <div id="entity-results"></div>
          <div id="member-results"></div>
        </div>
      </div>
      <div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;">
        <div id="content-container" style="-webkit-overflow-scrolling: touch;">
          <div id="subpackage-spacer">
            <div id="packages">
              <h1>Packages</h1>
              <ul>
                <li name="_root_.root" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="_root_"></a><a id="root:_root_"></a>
      <span class="permalink">
      <a href="../../../../index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../index.html"><span class="name">root</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="_root_.io" visbl="pub" class="indented1 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="io"></a><a id="io:io"></a>
      <span class="permalink">
      <a href="../../../../io/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../index.html"><span class="name">io</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="io.smartdatalake" visbl="pub" class="indented2 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="smartdatalake"></a><a id="smartdatalake:smartdatalake"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../index.html"><span class="name">smartdatalake</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../index.html" class="extype" name="io">io</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow" visbl="pub" class="indented3 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="workflow"></a><a id="workflow:workflow"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../index.html"><span class="name">workflow</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../index.html" class="extype" name="io.smartdatalake">smartdatalake</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="dataobject"></a><a id="dataobject:dataobject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="index.html"><span class="name">dataobject</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a></dd></dl></div>
    </li><li class="current-entities indented4">
                        <a class="object" href="AccessTableDataObject$.html" title=""></a>
                        <a class="class" href="AccessTableDataObject.html" title="DataObject of type JDBC / Access."></a>
                        <a href="AccessTableDataObject.html" title="DataObject of type JDBC / Access.">AccessTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ActionsExporterDataObject$.html" title=""></a>
                        <a class="class" href="ActionsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all io.smartdatalake.workflow.action.Actions that are registered in the current InstanceRegistry."></a>
                        <a href="ActionsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all io.smartdatalake.workflow.action.Actions that are registered in the current InstanceRegistry.">ActionsExporterDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="AvroFileDataObject$.html" title=""></a>
                        <a class="class" href="AvroFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Avro data source."></a>
                        <a href="AvroFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Avro data source.">AvroFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="CanHandlePartitions.html" title="A trait to be implemented by DataObjects which store partitioned data"></a>
                        <a href="CanHandlePartitions.html" title="A trait to be implemented by DataObjects which store partitioned data">CanHandlePartitions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ConnectionTestException.html" title=""></a>
                        <a href="ConnectionTestException.html" title="">ConnectionTestException</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CsvFileDataObject$.html" title=""></a>
                        <a class="class" href="CsvFileDataObject.html" title="A DataObject backed by a comma-separated value (CSV) data source."></a>
                        <a href="CsvFileDataObject.html" title="A DataObject backed by a comma-separated value (CSV) data source.">CsvFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CustomDfDataObject$.html" title=""></a>
                        <a class="class" href="CustomDfDataObject.html" title="Generic DataObject containing a config object."></a>
                        <a href="CustomDfDataObject.html" title="Generic DataObject containing a config object.">CustomDfDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CustomFileDataObject$.html" title=""></a>
                        <a class="class" href="CustomFileDataObject.html" title=""></a>
                        <a href="CustomFileDataObject.html" title="">CustomFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="DataObject.html" title="This is the root trait for every DataObject."></a>
                        <a href="DataObject.html" title="This is the root trait for every DataObject.">DataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataObjectMetadata.html" title="Additional metadata for a DataObject"></a>
                        <a href="DataObjectMetadata.html" title="Additional metadata for a DataObject">DataObjectMetadata</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="DataObjectsExporterDataObject$.html" title=""></a>
                        <a class="class" href="DataObjectsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all DataObjects that are registered in the current InstanceRegistry."></a>
                        <a href="DataObjectsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all DataObjects that are registered in the current InstanceRegistry.">DataObjectsExporterDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ExcelFileDataObject$.html" title=""></a>
                        <a class="class" href="ExcelFileDataObject.html" title="A DataObject backed by an Microsoft Excel data source."></a>
                        <a href="ExcelFileDataObject.html" title="A DataObject backed by an Microsoft Excel data source.">ExcelFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ExcelOptions.html" title="Options passed to org.apache.spark.sql.DataFrameReader and org.apache.spark.sql.DataFrameWriter for reading and writing Microsoft Excel files."></a>
                        <a href="ExcelOptions.html" title="Options passed to org.apache.spark.sql.DataFrameReader and org.apache.spark.sql.DataFrameWriter for reading and writing Microsoft Excel files.">ExcelOptions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ForeignKey.html" title="Foreign key definition"></a>
                        <a href="ForeignKey.html" title="Foreign key definition">ForeignKey</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="HiveTableDataObject$.html" title=""></a>
                        <a class="class" href="HiveTableDataObject.html" title="DataObject of type Hive."></a>
                        <a href="HiveTableDataObject.html" title="DataObject of type Hive.">HiveTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="HttpProxyConfig.html" title=""></a>
                        <a href="HttpProxyConfig.html" title="">HttpProxyConfig</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="HttpTimeoutConfig.html" title=""></a>
                        <a href="HttpTimeoutConfig.html" title="">HttpTimeoutConfig</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="JdbcTableDataObject$.html" title=""></a>
                        <a class="class" href="JdbcTableDataObject.html" title="DataObject of type JDBC."></a>
                        <a href="JdbcTableDataObject.html" title="DataObject of type JDBC.">JdbcTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="JsonFileDataObject$.html" title=""></a>
                        <a class="class" href="JsonFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by a JSON data source."></a>
                        <a href="JsonFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by a JSON data source.">JsonFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="PKViolatorsDataObject$.html" title=""></a>
                        <a class="class" href="PKViolatorsDataObject.html" title="Checks for Primary Key violations for all DataObjects with Primary Keys defined that are registered in the current InstanceRegistry."></a>
                        <a href="PKViolatorsDataObject.html" title="Checks for Primary Key violations for all DataObjects with Primary Keys defined that are registered in the current InstanceRegistry.">PKViolatorsDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ParquetFileDataObject$.html" title=""></a>
                        <a class="class" href="" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Apache Hive data source."></a>
                        <a href="" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Apache Hive data source.">ParquetFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="RawFileDataObject$.html" title=""></a>
                        <a class="class" href="RawFileDataObject.html" title="DataObject of type raw for files with unknown content."></a>
                        <a href="RawFileDataObject.html" title="DataObject of type raw for files with unknown content.">RawFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SFtpFileRefDataObject$.html" title=""></a>
                        <a class="class" href="SFtpFileRefDataObject.html" title="Connects to SFtp files Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot; The following authentication mechanisms are supported -&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server."></a>
                        <a href="SFtpFileRefDataObject.html" title="Connects to SFtp files Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot; The following authentication mechanisms are supported -&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server.">SFtpFileRefDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Table.html" title="Table attributes"></a>
                        <a href="Table.html" title="Table attributes">Table</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="TickTockHiveTableDataObject$.html" title=""></a>
                        <a class="class" href="TickTockHiveTableDataObject.html" title=""></a>
                        <a href="TickTockHiveTableDataObject.html" title="">TickTockHiveTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="WebserviceFileDataObject$.html" title=""></a>
                        <a class="class" href="WebserviceFileDataObject.html" title="DataObject to call webservice and return response as InputStream This is implemented as FileRefDataObject because the response is treated as some file content."></a>
                        <a href="WebserviceFileDataObject.html" title="DataObject to call webservice and return response as InputStream This is implemented as FileRefDataObject because the response is treated as some file content.">WebserviceFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="WebservicePartitionDefinition.html" title=""></a>
                        <a href="WebservicePartitionDefinition.html" title="">WebservicePartitionDefinition</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="XmlFileDataObject$.html" title=""></a>
                        <a class="class" href="XmlFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an XML data source."></a>
                        <a href="XmlFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an XML data source.">XmlFileDataObject</a>
                      </li>
              </ul>
            </div>
          </div>
          <div id="content">
            <body class="class type">
      <div id="definition">
        <a href="ParquetFileDataObject$.html" title="See companion object"><div class="big-circle class-companion-object">c</div></a>
        <p id="owner"><a href="../../../index.html" class="extype" name="io">io</a>.<a href="../../index.html" class="extype" name="io.smartdatalake">smartdatalake</a>.<a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a>.<a href="index.html" class="extype" name="io.smartdatalake.workflow.dataobject">dataobject</a></p>
        <h1><a href="ParquetFileDataObject$.html" title="See companion object">ParquetFileDataObject</a><span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span></h1>
        <h3><span class="morelinks"><div>
            Companion <a href="ParquetFileDataObject$.html" title="See companion object">object ParquetFileDataObject</a>
          </div></span></h3>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <span class="name">ParquetFileDataObject</span><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="parquetOptions">parquetOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">SparkFileDataObjectWithEmbeddedSchema</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>

      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an Apache Hive data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on Parquet formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively.
</p></div><dl class="paramcmts block"><dt class="param">id</dt><dd class="cmt"><p>unique name of this data object</p></dd><dt class="param">path</dt><dd class="cmt"><p>Hadoop directory where this data object reads/writes it's files.
            If it doesn't contain scheme and authority, the connections pathPrefix is applied. If pathPrefix is not
            defined or doesn't define scheme and authority, default schema and authority is applied.
            Optionally defined partitions are appended with hadoop standard partition layout to this path.
            Only files ending with *.parquet* are considered as data for this DataObject.</p></dd><dt class="param">partitions</dt><dd class="cmt"><p>partition columns for this data object</p></dd><dt class="param">parquetOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and
                      <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional schema for the spark data frame to be validated on read and write. Note: Existing Parquet files
              contain a source schema. Therefore, this schema is ignored when reading from existing Parquet files.
              As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>spark <span class="extype" name="SaveMode">SaveMode</span> to use when writing files, default is &quot;overwrite&quot;</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">acl</dt><dd class="cmt"><p>override connections permissions for files created with this connection</p></dd><dt class="param">connectionId</dt><dd class="cmt"><p>optional id of <a href="../connection/HadoopFileConnection.html" class="extype" name="io.smartdatalake.workflow.connection.HadoopFileConnection">io.smartdatalake.workflow.connection.HadoopFileConnection</a></p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd><dt class="param">metadata</dt><dd class="cmt"><p>Metadata describing this data object.</p></dd></dl><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl><div class="toggleContainer block">
          <span class="toggle">
            Linear Supertypes
          </span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="scala.Product">Product</span>, <span class="extype" name="scala.Equals">Equals</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">SparkFileDataObjectWithEmbeddedSchema</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.SchemaValidation">SchemaValidation</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.UserDefinedSchema">UserDefinedSchema</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateStreamingDataFrame">CanCreateStreamingDataFrame</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject">HadoopFileDataObject</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream">CanCreateOutputStream</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">CanCreateInputStream</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">FileRefDataObject</span>, <span class="extype" name="io.smartdatalake.workflow.dataobject.FileDataObject">FileDataObject</span>, <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a>, <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>, <a href="../AtlasExportable.html" class="extype" name="io.smartdatalake.workflow.AtlasExportable">AtlasExportable</a>, <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span>, <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>], <span class="extype" name="io.smartdatalake.config.SdlConfigObject">SdlConfigObject</span>, <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div class="toggle"></div>
        <div id="memberfilter">
          <i class="material-icons arrow"></i>
          <span class="input">
            <input id="mbrsel-input" placeholder="Filter all members" type="text" accesskey="/" />
          </span>
          <i class="clear material-icons"></i>
        </div>
        <div id="filterby">
          <div id="order">
            <span class="filtertype">Ordering</span>
            <ol>
              
              <li class="alpha in"><span>Alphabetic</span></li>
              <li class="inherit out"><span>By Inheritance</span></li>
            </ol>
          </div>
          <div class="ancestors">
                  <span class="filtertype">Inherited<br />
                  </span>
                  <ol id="linearization">
                    <li class="in" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject"><span>ParquetFileDataObject</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="scala.Product"><span>Product</span></li><li class="in" name="scala.Equals"><span>Equals</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema"><span>SparkFileDataObjectWithEmbeddedSchema</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject"><span>SparkFileDataObject</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.SchemaValidation"><span>SchemaValidation</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.UserDefinedSchema"><span>UserDefinedSchema</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanCreateStreamingDataFrame"><span>CanCreateStreamingDataFrame</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame"><span>CanWriteDataFrame</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame"><span>CanCreateDataFrame</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject"><span>HadoopFileDataObject</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream"><span>CanCreateOutputStream</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream"><span>CanCreateInputStream</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.FileRefDataObject"><span>FileRefDataObject</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.FileDataObject"><span>FileDataObject</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions"><span>CanHandlePartitions</span></li><li class="in" name="io.smartdatalake.workflow.dataobject.DataObject"><span>DataObject</span></li><li class="in" name="io.smartdatalake.workflow.AtlasExportable"><span>AtlasExportable</span></li><li class="in" name="io.smartdatalake.util.misc.SmartDataLakeLogger"><span>SmartDataLakeLogger</span></li><li class="in" name="io.smartdatalake.config.ParsableFromConfig"><span>ParsableFromConfig</span></li><li class="in" name="io.smartdatalake.config.SdlConfigObject"><span>SdlConfigObject</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                  </ol>
                </div><div class="ancestors">
              <span class="filtertype"></span>
              <ol>
                <li class="hideall out"><span>Hide All</span></li>
                <li class="showall in"><span>Show All</span></li>
              </ol>
            </div>
          <div id="visbl">
              <span class="filtertype">Visibility</span>
              <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
            </div>
        </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#&lt;init&gt;" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(id:io.smartdatalake.config.SdlConfigObject.DataObjectId,path:String,partitions:Seq[String],parquetOptions:Option[Map[String,String]],schema:Option[org.apache.spark.sql.types.StructType],schemaMin:Option[org.apache.spark.sql.types.StructType],saveMode:io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode,sparkRepartition:Option[io.smartdatalake.util.hdfs.SparkRepartitionDef],acl:Option[io.smartdatalake.util.misc.AclDef],connectionId:Option[io.smartdatalake.config.SdlConfigObject.ConnectionId],filenameColumn:Option[String],expectedPartitionsCondition:Option[String],metadata:Option[io.smartdatalake.workflow.dataobject.DataObjectMetadata])(implicitinstanceRegistry:io.smartdatalake.config.InstanceRegistry):io.smartdatalake.workflow.dataobject.ParquetFileDataObject"></a><a id="&lt;init&gt;:ParquetFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#&lt;init&gt;(id:io.smartdatalake.config.SdlConfigObject.DataObjectId,path:String,partitions:Seq[String],parquetOptions:Option[Map[String,String]],schema:Option[org.apache.spark.sql.types.StructType],schemaMin:Option[org.apache.spark.sql.types.StructType],saveMode:io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode,sparkRepartition:Option[io.smartdatalake.util.hdfs.SparkRepartitionDef],acl:Option[io.smartdatalake.util.misc.AclDef],connectionId:Option[io.smartdatalake.config.SdlConfigObject.ConnectionId],filenameColumn:Option[String],expectedPartitionsCondition:Option[String],metadata:Option[io.smartdatalake.workflow.dataobject.DataObjectMetadata])(implicitinstanceRegistry:io.smartdatalake.config.InstanceRegistry):io.smartdatalake.workflow.dataobject.ParquetFileDataObject" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">ParquetFileDataObject</span><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="parquetOptions">parquetOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span>
      </span>
      
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="paramcmts block"><dt class="param">id</dt><dd class="cmt"><p>unique name of this data object</p></dd><dt class="param">path</dt><dd class="cmt"><p>Hadoop directory where this data object reads/writes it's files.
            If it doesn't contain scheme and authority, the connections pathPrefix is applied. If pathPrefix is not
            defined or doesn't define scheme and authority, default schema and authority is applied.
            Optionally defined partitions are appended with hadoop standard partition layout to this path.
            Only files ending with *.parquet* are considered as data for this DataObject.</p></dd><dt class="param">partitions</dt><dd class="cmt"><p>partition columns for this data object</p></dd><dt class="param">parquetOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and
                      <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional schema for the spark data frame to be validated on read and write. Note: Existing Parquet files
              contain a source schema. Therefore, this schema is ignored when reading from existing Parquet files.
              As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>spark <span class="extype" name="SaveMode">SaveMode</span> to use when writing files, default is &quot;overwrite&quot;</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">acl</dt><dd class="cmt"><p>override connections permissions for files created with this connection</p></dd><dt class="param">connectionId</dt><dd class="cmt"><p>optional id of <a href="../connection/HadoopFileConnection.html" class="extype" name="io.smartdatalake.workflow.connection.HadoopFileConnection">io.smartdatalake.workflow.connection.HadoopFileConnection</a></p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd><dt class="param">metadata</dt><dd class="cmt"><p>Metadata describing this data object.</p></dd></dl></div>
    </li></ol>
            </div>

        

        

        <div class="values members">
              <h3>Value Members</h3>
              <ol>
                <li name="scala.AnyRef#!=" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a><a id="!=(Any):Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#!=(x$1:Any):Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html###():Int" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a><a id="==(Any):Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#==(x$1:Any):Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#acl" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="acl:Option[io.smartdatalake.util.misc.AclDef]"></a><a id="acl:Option[AclDef]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#acl:Option[io.smartdatalake.util.misc.AclDef]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">acl</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Return the ACL definition for the Hadoop path of this DataObject
</p><div class="fullcomment"><div class="comment cmt"><p>Return the ACL definition for the Hadoop path of this DataObject
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → HadoopFileDataObject</dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.hadoop.fs.permission.AclEntry">org.apache.hadoop.fs.permission.AclEntry</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame#addFieldIfNotExisting" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="addFieldIfNotExisting(writeSchema:org.apache.spark.sql.types.StructType,colName:String,dataType:org.apache.spark.sql.types.DataType):org.apache.spark.sql.types.StructType"></a><a id="addFieldIfNotExisting(StructType,String,DataType):StructType"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#addFieldIfNotExisting(writeSchema:org.apache.spark.sql.types.StructType,colName:String,dataType:org.apache.spark.sql.types.DataType):org.apache.spark.sql.types.StructType" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">addFieldIfNotExisting</span><span class="params">(<span name="writeSchema">writeSchema: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>, <span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="dataType">dataType: <span class="extype" name="org.apache.spark.sql.types.DataType">DataType</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>CanCreateDataFrame</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#afterRead" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="afterRead(df:org.apache.spark.sql.DataFrame)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame"></a><a id="afterRead(DataFrame)(SparkSession):DataFrame"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#afterRead(df:org.apache.spark.sql.DataFrame)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">afterRead</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>
      </span>
      
      <p class="shortcomment cmt">Callback that enables potential transformation to be applied to <code>df</code> after the data is read.</p><div class="fullcomment"><div class="comment cmt"><p>Callback that enables potential transformation to be applied to <code>df</code> after the data is read.</p><p>Default is to validate the <code>schemaMin</code> and not apply any modification.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#applyAcls" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="applyAcls(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="applyAcls(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#applyAcls(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">applyAcls</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a>] </dd><dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#asInstanceOf[T0]:T0" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObject#atlasName" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="atlasName:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#atlasName:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">atlasName</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> → <a href="../AtlasExportable.html" class="extype" name="io.smartdatalake.workflow.AtlasExportable">AtlasExportable</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.AtlasExportable#atlasQualifiedName" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="atlasQualifiedName(prefix:String):String"></a><a id="atlasQualifiedName(String):String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#atlasQualifiedName(prefix:String):String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">atlasQualifiedName</span><span class="params">(<span name="prefix">prefix: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../AtlasExportable.html" class="extype" name="io.smartdatalake.workflow.AtlasExportable">AtlasExportable</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#beforeWrite" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="beforeWrite(df:org.apache.spark.sql.DataFrame)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame"></a><a id="beforeWrite(DataFrame)(SparkSession):DataFrame"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#beforeWrite(df:org.apache.spark.sql.DataFrame)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">beforeWrite</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>
      </span>
      
      <p class="shortcomment cmt">Callback that enables potential transformation to be applied to <code>df</code> before the data is written.</p><div class="fullcomment"><div class="comment cmt"><p>Callback that enables potential transformation to be applied to <code>df</code> before the data is written.</p><p>Default is to validate the <code>schemaMin</code> and not apply any modification.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SparkFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#checkFilesExisting" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="checkFilesExisting(implicitsession:org.apache.spark.sql.SparkSession):Boolean"></a><a id="checkFilesExisting(SparkSession):Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#checkFilesExisting(implicitsession:org.apache.spark.sql.SparkSession):Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">checkFilesExisting</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <p class="shortcomment cmt">Check if the input files exist.</p><div class="fullcomment"><div class="comment cmt"><p>Check if the input files exist.
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>HadoopFileDataObject</dd><dt>Exceptions thrown</dt><dd><span class="cmt"><p><span class="extype" name="IllegalArgumentException"><code>IllegalArgumentException</code></span> if <code>failIfFilesMissing</code> = true and no files found at <code>path</code>.</p></span></dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a><a id="clone():AnyRef"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#clone():Object" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<span class="extype" name="java.lang">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
                <span class="name">@native</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#connection" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="connection:Option[io.smartdatalake.workflow.connection.HadoopFileConnection]"></a><a id="connection:Option[HadoopFileConnection]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#connection:Option[io.smartdatalake.workflow.connection.HadoopFileConnection]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">connection</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<a href="../connection/HadoopFileConnection.html" class="extype" name="io.smartdatalake.workflow.connection.HadoopFileConnection">HadoopFileConnection</a>]</span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#connectionId" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="connectionId:Option[io.smartdatalake.config.SdlConfigObject.ConnectionId]"></a><a id="connectionId:Option[ConnectionId]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#connectionId:Option[io.smartdatalake.config.SdlConfigObject.ConnectionId]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">connectionId</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Return the connection id.</p><div class="fullcomment"><div class="comment cmt"><p>Return the connection id.</p><p>Connection defines path prefix (scheme, authority, base path) and ACL's in central location.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#createEmptyPartition" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createEmptyPartition(partitionValues:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="createEmptyPartition(PartitionValues)(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#createEmptyPartition(partitionValues:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createEmptyPartition</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">create empty partition
</p><div class="fullcomment"><div class="comment cmt"><p>create empty partition
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#createInputStream" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createInputStream(path:String)(implicitsession:org.apache.spark.sql.SparkSession):java.io.InputStream"></a><a id="createInputStream(String)(SparkSession):InputStream"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#createInputStream(path:String)(implicitsession:org.apache.spark.sql.SparkSession):java.io.InputStream" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createInputStream</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="java.io.InputStream">InputStream</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → CanCreateInputStream</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#createOutputStream" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createOutputStream(path:String,overwrite:Boolean)(implicitsession:org.apache.spark.sql.SparkSession):java.io.OutputStream"></a><a id="createOutputStream(String,Boolean)(SparkSession):OutputStream"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#createOutputStream(path:String,overwrite:Boolean)(implicitsession:org.apache.spark.sql.SparkSession):java.io.OutputStream" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createOutputStream</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="overwrite">overwrite: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="java.io.OutputStream">OutputStream</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → CanCreateOutputStream</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#createReadSchema" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createReadSchema(writeSchema:org.apache.spark.sql.types.StructType)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.types.StructType"></a><a id="createReadSchema(StructType)(SparkSession):StructType"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#createReadSchema(writeSchema:org.apache.spark.sql.types.StructType)(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.types.StructType" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createReadSchema</span><span class="params">(<span name="writeSchema">writeSchema: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>
      </span>
      
      <p class="shortcomment cmt">Creates the read schema based on a given write schema.</p><div class="fullcomment"><div class="comment cmt"><p>Creates the read schema based on a given write schema.
Normally this is the same, but some DataObjects can remove &amp; add columns on read (e.g. KafkaTopicDataObject, SparkFileDataObject)
In this cases we have to break the DataFrame lineage und create a dummy DataFrame in init phase.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject → CanCreateDataFrame</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#deleteAll" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="deleteAll(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="deleteAll(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#deleteAll(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">deleteAll</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Delete all data.</p><div class="fullcomment"><div class="comment cmt"><p>Delete all data. This is used to implement SaveMode.Overwrite.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#deleteAllFiles" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="deleteAllFiles(path:org.apache.hadoop.fs.Path)(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="deleteAllFiles(Path)(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#deleteAllFiles(path:org.apache.hadoop.fs.Path)(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">deleteAllFiles</span><span class="params">(<span name="path">path: <span class="extype" name="org.apache.hadoop.fs.Path">Path</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">delete all files inside given path recursively
</p><div class="fullcomment"><div class="comment cmt"><p>delete all files inside given path recursively
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#deleteFileRefs" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="deleteFileRefs(fileRefs:Seq[io.smartdatalake.workflow.dataobject.FileRef])(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="deleteFileRefs(Seq[FileRef])(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#deleteFileRefs(fileRefs:Seq[io.smartdatalake.workflow.dataobject.FileRef])(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">deleteFileRefs</span><span class="params">(<span name="fileRefs">fileRefs: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="io.smartdatalake.workflow.dataobject.FileRef">FileRef</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Delete given files.</p><div class="fullcomment"><div class="comment cmt"><p>Delete given files. This is used to cleanup files after they are processed.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#deletePartitions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="deletePartitions(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="deletePartitions(Seq[PartitionValues])(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#deletePartitions(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">deletePartitions</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Delete Hadoop Partitions.</p><div class="fullcomment"><div class="comment cmt"><p>Delete Hadoop Partitions.</p><p>if there is no value for a partition column before the last partition column given, the partition path will be exploded
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#deletePartitionsFiles" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="deletePartitionsFiles(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="deletePartitionsFiles(Seq[PartitionValues])(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#deletePartitionsFiles(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">deletePartitionsFiles</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Delete files inside Hadoop Partitions, but keep partition directory to preserve ACLs</p><div class="fullcomment"><div class="comment cmt"><p>Delete files inside Hadoop Partitions, but keep partition directory to preserve ACLs</p><p>if there is no value for a partition column before the last partition column given, the partition path will be exploded
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a><a id="eq(AnyRef):Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#eq(x$1:AnyRef):Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#expectedPartitionsCondition" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="expectedPartitionsCondition:Option[String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#expectedPartitionsCondition:Option[String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">expectedPartitionsCondition</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Definition of partitions that are expected to exists.</p><div class="fullcomment"><div class="comment cmt"><p>Definition of partitions that are expected to exists.
This is used to validate that partitions being read exists and don't return no data.
Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
example: &quot;elements['yourColName'] &gt; 2017&quot;</p></div><dl class="paramcmts block"><dt>returns</dt><dd class="cmt"><p>true if partition is expected to exist.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileRefDataObject#extractPartitionValuesFromPath" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="extractPartitionValuesFromPath(filePath:String):io.smartdatalake.util.hdfs.PartitionValues"></a><a id="extractPartitionValuesFromPath(String):PartitionValues"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#extractPartitionValuesFromPath(filePath:String):io.smartdatalake.util.hdfs.PartitionValues" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">extractPartitionValuesFromPath</span><span class="params">(<span name="filePath">filePath: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a></span>
      </span>
      
      <p class="shortcomment cmt">Extract partition values from a given file path
</p><div class="fullcomment"><div class="comment cmt"><p>Extract partition values from a given file path
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#factory" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="factory:io.smartdatalake.config.FromConfigFactory[io.smartdatalake.workflow.dataobject.DataObject]"></a><a id="factory:FromConfigFactory[DataObject]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#factory:io.smartdatalake.config.FromConfigFactory[io.smartdatalake.workflow.dataobject.DataObject]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">factory</span><span class="result">: <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Returns the factory that can parse this type (that is, type <code>CO</code>).</p><div class="fullcomment"><div class="comment cmt"><p>Returns the factory that can parse this type (that is, type <code>CO</code>).</p><p>Typically, implementations of this method should return the companion object of the implementing class.
The companion object in turn should implement <span class="extype" name="FromConfigFactory">FromConfigFactory</span>.
</p></div><dl class="paramcmts block"><dt>returns</dt><dd class="cmt"><p>the factory (object) for this class.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → ParsableFromConfig</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#failIfFilesMissing" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="failIfFilesMissing:Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#failIfFilesMissing:Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">failIfFilesMissing</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <p class="shortcomment cmt">Configure whether <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s should fail if the input file(s) are missing
on the file system.</p><div class="fullcomment"><div class="comment cmt"><p>Configure whether <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s should fail if the input file(s) are missing
on the file system.</p><p>Default is false.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#fileName" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fileName:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#fileName:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">fileName</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <p class="shortcomment cmt">Definition of fileName.</p><div class="fullcomment"><div class="comment cmt"><p>Definition of fileName. Default is an asterix to match everything.
This is concatenated with the partition layout to search for files.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#filenameColumn" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="filenameColumn:Option[String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#filenameColumn:Option[String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">filenameColumn</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">The name of the (optional) additional column containing the source filename
</p><div class="fullcomment"><div class="comment cmt"><p>The name of the (optional) additional column containing the source filename
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SparkFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#filesystem" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="filesystem(implicitsession:org.apache.spark.sql.SparkSession):org.apache.hadoop.fs.FileSystem"></a><a id="filesystem(SparkSession):FileSystem"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#filesystem(implicitsession:org.apache.spark.sql.SparkSession):org.apache.hadoop.fs.FileSystem" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filesystem</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="org.apache.hadoop.fs.FileSystem">FileSystem</span></span>
      </span>
      
      <p class="shortcomment cmt">Create a hadoop <span class="extype" name="FileSystem">FileSystem</span> API handle for the provided <span class="extype" name="SparkSession">SparkSession</span>.</p><div class="fullcomment"><div class="comment cmt"><p>Create a hadoop <span class="extype" name="FileSystem">FileSystem</span> API handle for the provided <span class="extype" name="SparkSession">SparkSession</span>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#filterPartitionsExisting" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="filterPartitionsExisting(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.util.hdfs.PartitionValues]"></a><a id="filterPartitionsExisting(Seq[PartitionValues])(SparkSession):Seq[PartitionValues]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#filterPartitionsExisting(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.util.hdfs.PartitionValues]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filterPartitionsExisting</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Filters only existing partition.</p><div class="fullcomment"><div class="comment cmt"><p>Filters only existing partition.
Note that partition values to check don't need to have a key/value defined for every partition column.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject</dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#finalize():Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<span class="extype" name="java.lang">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#format" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="format:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#format:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">format</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      
      <p class="shortcomment cmt">The Spark-Format provider to be used
</p><div class="fullcomment"><div class="comment cmt"><p>The Spark-Format provider to be used
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SparkFileDataObject</dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getClass():Class[_]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd>
                <span class="name">@native</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#getConcretePaths" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getConcretePaths(pv:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Seq[org.apache.hadoop.fs.Path]"></a><a id="getConcretePaths(PartitionValues)(SparkSession):Seq[Path]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getConcretePaths(pv:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Seq[org.apache.hadoop.fs.Path]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getConcretePaths</span><span class="params">(<span name="pv">pv: <a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="org.apache.hadoop.fs.Path">Path</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Generate all paths for given partition values exploding undefined partitions before the last given partition value.</p><div class="fullcomment"><div class="comment cmt"><p>Generate all paths for given partition values exploding undefined partitions before the last given partition value.
Use case: Reading all files from a given path with spark cannot contain wildcards.
  If there are partitions without given partition value before the last partition value given, they must be searched with globs.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObject#getConnection" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getConnection[T&lt;:io.smartdatalake.workflow.connection.Connection](connectionId:io.smartdatalake.config.SdlConfigObject.ConnectionId)(implicitregistry:io.smartdatalake.config.InstanceRegistry,implicitct:scala.reflect.ClassTag[T],implicittt:reflect.runtime.universe.TypeTag[T]):T"></a><a id="getConnection[T&lt;:Connection](ConnectionId)(InstanceRegistry,ClassTag[T],scala.reflect.api.JavaUniverse.TypeTag[T]):T"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getConnection[T&lt;:io.smartdatalake.workflow.connection.Connection](connectionId:io.smartdatalake.config.SdlConfigObject.ConnectionId)(implicitregistry:io.smartdatalake.config.InstanceRegistry,implicitct:scala.reflect.ClassTag[T],implicittt:reflect.runtime.universe.TypeTag[T]):T" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getConnection</span><span class="tparams">[<span name="T">T &lt;: <span class="extype" name="io.smartdatalake.workflow.connection.Connection">Connection</span></span>]</span><span class="params">(<span name="connectionId">connectionId: <a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="registry">registry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>, <span name="ct">ct: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnection.T">T</span>]</span>, <span name="tt">tt: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnection.T">T</span>]</span>)</span><span class="result">: <span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnection.T">T</span></span>
      </span>
      
      <p class="shortcomment cmt">Handle class cast exception when getting objects from instance registry
</p><div class="fullcomment"><div class="comment cmt"><p>Handle class cast exception when getting objects from instance registry
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObject#getConnectionReg" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getConnectionReg[T&lt;:io.smartdatalake.workflow.connection.Connection](connectionId:io.smartdatalake.config.SdlConfigObject.ConnectionId,registry:io.smartdatalake.config.InstanceRegistry)(implicitct:scala.reflect.ClassTag[T],implicittt:reflect.runtime.universe.TypeTag[T]):T"></a><a id="getConnectionReg[T&lt;:Connection](ConnectionId,InstanceRegistry)(ClassTag[T],scala.reflect.api.JavaUniverse.TypeTag[T]):T"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getConnectionReg[T&lt;:io.smartdatalake.workflow.connection.Connection](connectionId:io.smartdatalake.config.SdlConfigObject.ConnectionId,registry:io.smartdatalake.config.InstanceRegistry)(implicitct:scala.reflect.ClassTag[T],implicittt:reflect.runtime.universe.TypeTag[T]):T" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getConnectionReg</span><span class="tparams">[<span name="T">T &lt;: <span class="extype" name="io.smartdatalake.workflow.connection.Connection">Connection</span></span>]</span><span class="params">(<span name="connectionId">connectionId: <a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a></span>, <span name="registry">registry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="ct">ct: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnectionReg.T">T</span>]</span>, <span name="tt">tt: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnectionReg.T">T</span>]</span>)</span><span class="result">: <span class="extype" name="io.smartdatalake.workflow.dataobject.DataObject.getConnectionReg.T">T</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#getDataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getDataFrame(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):org.apache.spark.sql.DataFrame"></a><a id="getDataFrame(Seq[PartitionValues])(SparkSession,ActionPipelineContext):DataFrame"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getDataFrame(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):org.apache.spark.sql.DataFrame" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getDataFrame</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>
      </span>
      
      <p class="shortcomment cmt">Constructs an Apache Spark <span class="extype" name="DataFrame">DataFrame</span> from the underlying file content.</p><div class="fullcomment"><div class="comment cmt"><p>Constructs an Apache Spark <span class="extype" name="DataFrame">DataFrame</span> from the underlying file content.
</p></div><dl class="paramcmts block"><dt class="param">session</dt><dd class="cmt"><p>the current <span class="extype" name="SparkSession">SparkSession</span>.</p></dd><dt>returns</dt><dd class="cmt"><p>a new <span class="extype" name="DataFrame">DataFrame</span> containing the data stored in the file at <code>path</code></p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject → CanCreateDataFrame</dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="DataFrameReader">DataFrameReader</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#getFileRefs" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getFileRefs(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.workflow.dataobject.FileRef]"></a><a id="getFileRefs(Seq[PartitionValues])(SparkSession):Seq[FileRef]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getFileRefs(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.workflow.dataobject.FileRef]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getFileRefs</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="io.smartdatalake.workflow.dataobject.FileRef">FileRef</span>]</span>
      </span>
      
      <p class="shortcomment cmt">List files for given partition values
</p><div class="fullcomment"><div class="comment cmt"><p>List files for given partition values
</p></div><dl class="paramcmts block"><dt class="param">partitionValues</dt><dd class="cmt"><p>List of partition values to be filtered. If empty all files in root path of DataObject will be listed.</p></dd><dt>returns</dt><dd class="cmt"><p>List of <span class="extype" name="FileRef">FileRef</span>s</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileRefDataObject#getPartitionString" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getPartitionString(partitionValues:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Option[String]"></a><a id="getPartitionString(PartitionValues)(SparkSession):Option[String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getPartitionString(partitionValues:io.smartdatalake.util.hdfs.PartitionValues)(implicitsession:org.apache.spark.sql.SparkSession):Option[String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getPartitionString</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">get partition values formatted by partition layout
</p><div class="fullcomment"><div class="comment cmt"><p>get partition values formatted by partition layout
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#getPath" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getPath:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getPath:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getPath</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <p class="shortcomment cmt">Method for subclasses to override the base path for this DataObject.</p><div class="fullcomment"><div class="comment cmt"><p>Method for subclasses to override the base path for this DataObject.
This is for instance needed if pathPrefix is defined in a connection.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#getSchema" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getSchema(sourceExists:Boolean):Option[org.apache.spark.sql.types.StructType]"></a><a id="getSchema(Boolean):Option[StructType]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getSchema(sourceExists:Boolean):Option[org.apache.spark.sql.types.StructType]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getSchema</span><span class="params">(<span name="sourceExists">sourceExists: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Returns the user-defined schema for reading from the data source.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the user-defined schema for reading from the data source. By default, this should return <code>schema</code> but it
may be customized by data objects that have a source schema and ignore the user-defined schema on read operations.</p><p>If a user-defined schema is returned, it overrides any schema inference. If no user-defined schema is set, the
schema may be inferred depending on the configuration and type of data frame reader.
</p></div><dl class="paramcmts block"><dt class="param">sourceExists</dt><dd class="cmt"><p>Whether the source file/table exists already. Existing sources may have a source schema.</p></dd><dt>returns</dt><dd class="cmt"><p>The schema to use for the data frame reader when reading from the source.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileRefDataObject#getSearchPaths" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getSearchPaths(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[(io.smartdatalake.util.hdfs.PartitionValues,String)]"></a><a id="getSearchPaths(Seq[PartitionValues])(SparkSession):Seq[(PartitionValues,String)]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getSearchPaths(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession):Seq[(io.smartdatalake.util.hdfs.PartitionValues,String)]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getSearchPaths</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[(<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>, <span class="extype" name="scala.Predef.String">String</span>)]</span>
      </span>
      
      <p class="shortcomment cmt">prepare paths to be searched
</p><div class="fullcomment"><div class="comment cmt"><p>prepare paths to be searched
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#getStreamingDataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getStreamingDataFrame(options:Map[String,String],pipelineSchema:Option[org.apache.spark.sql.types.StructType])(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame"></a><a id="getStreamingDataFrame(Map[String,String],Option[StructType])(SparkSession):DataFrame"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#getStreamingDataFrame(options:Map[String,String],pipelineSchema:Option[org.apache.spark.sql.types.StructType])(implicitsession:org.apache.spark.sql.SparkSession):org.apache.spark.sql.DataFrame" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getStreamingDataFrame</span><span class="params">(<span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="pipelineSchema">pipelineSchema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject → CanCreateStreamingDataFrame</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#id" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="id:io.smartdatalake.config.SdlConfigObject.DataObjectId"></a><a id="id:DataObjectId"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#id:io.smartdatalake.config.SdlConfigObject.DataObjectId" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">id</span><span class="result">: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>
      </span>
      
      <p class="shortcomment cmt">A unique identifier for this instance.</p><div class="fullcomment"><div class="comment cmt"><p>A unique identifier for this instance.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> → SdlConfigObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#init" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="init(df:org.apache.spark.sql.DataFrame,partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit"></a><a id="init(DataFrame,Seq[PartitionValues])(SparkSession,ActionPipelineContext):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#init(df:org.apache.spark.sql.DataFrame,partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">init</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Called during init phase for checks and initialization.</p><div class="fullcomment"><div class="comment cmt"><p>Called during init phase for checks and initialization.
If possible dont change the system until execution phase.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject → CanWriteDataFrame</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#instanceRegistry" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="instanceRegistry:io.smartdatalake.config.InstanceRegistry"></a><a id="instanceRegistry:InstanceRegistry"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#instanceRegistry:io.smartdatalake.config.InstanceRegistry" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">instanceRegistry</span><span class="result">: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>
      </span>
      
      <p class="shortcomment cmt">Return the <span class="extype" name="InstanceRegistry">InstanceRegistry</span> parsed from the SDL configuration used for this run.</p><div class="fullcomment"><div class="comment cmt"><p>Return the <span class="extype" name="InstanceRegistry">InstanceRegistry</span> parsed from the SDL configuration used for this run.
</p></div><dl class="paramcmts block"><dt>returns</dt><dd class="cmt"><p>the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → HadoopFileDataObject</dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#isInstanceOf[T0]:Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#listPartitions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="listPartitions(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.util.hdfs.PartitionValues]"></a><a id="listPartitions(SparkSession):Seq[PartitionValues]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#listPartitions(implicitsession:org.apache.spark.sql.SparkSession):Seq[io.smartdatalake.util.hdfs.PartitionValues]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">listPartitions</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>
      </span>
      
      <p class="shortcomment cmt">List partitions on data object's root path
</p><div class="fullcomment"><div class="comment cmt"><p>List partitions on data object's root path
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd></dl></div>
    </li><li name="io.smartdatalake.util.misc.SmartDataLakeLogger#logger" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logger:org.slf4j.Logger"></a><a id="logger:Logger"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#logger:org.slf4j.Logger" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">lazy val</span>
      </span>
      <span class="symbol">
        <span class="name">logger</span><span class="result">: <span class="extype" name="org.slf4j.Logger">Logger</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>SmartDataLakeLogger</dd><dt>Annotations</dt><dd>
                <span class="name">@transient</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#metadata" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="metadata:Option[io.smartdatalake.workflow.dataobject.DataObjectMetadata]"></a><a id="metadata:Option[DataObjectMetadata]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#metadata:Option[io.smartdatalake.workflow.dataobject.DataObjectMetadata]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">metadata</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Additional metadata for the DataObject
</p><div class="fullcomment"><div class="comment cmt"><p>Additional metadata for the DataObject
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a><a id="ne(AnyRef):Boolean"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#ne(x$1:AnyRef):Boolean" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#notify():Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@native</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#notifyAll():Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@native</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#options" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="options:Map[String,String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#options:Map[String,String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">options</span><span class="result">: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Returns the configured options for the Spark <span class="extype" name="DataFrameReader">DataFrameReader</span>/<span class="extype" name="DataFrameWriter">DataFrameWriter</span>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the configured options for the Spark <span class="extype" name="DataFrameReader">DataFrameReader</span>/<span class="extype" name="DataFrameWriter">DataFrameWriter</span>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SparkFileDataObject</dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="DataFrameReader">DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="DataFrameWriter">DataFrameWriter</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#parquetOptions" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="parquetOptions:Option[Map[String,String]]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#parquetOptions:Option[Map[String,String]]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">parquetOptions</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]]</span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#partitionLayout" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="partitionLayout():Option[String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#partitionLayout():Option[String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">partitionLayout</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Return a <span class="extype" name="String">String</span> specifying the partition layout.</p><div class="fullcomment"><div class="comment cmt"><p>Return a <span class="extype" name="String">String</span> specifying the partition layout.</p><p>For Hadoop the default partition layout is colname1=&lt;value1&gt;/colname2=&lt;value2&gt;/.../
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#partitions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="partitions:Seq[String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#partitions:Seq[String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">partitions</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Definition of partition columns
</p><div class="fullcomment"><div class="comment cmt"><p>Definition of partition columns
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#path" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="path:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#path:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">path</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <p class="shortcomment cmt">The root path of the files that are handled by this DataObject.</p><div class="fullcomment"><div class="comment cmt"><p>The root path of the files that are handled by this DataObject.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → FileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#postWrite" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="postWrite(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit"></a><a id="postWrite(Seq[PartitionValues])(SparkSession,ActionPipelineContext):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#postWrite(partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">postWrite</span><span class="params">(<span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Runs operations after writing to <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
</p><div class="fullcomment"><div class="comment cmt"><p>Runs operations after writing to <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#preWrite" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="preWrite(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit"></a><a id="preWrite(SparkSession,ActionPipelineContext):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#preWrite(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">preWrite</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Runs operations before writing to <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
Note: As the transformed SubFeed doesnt yet exist in Action.preWrite, no partition values can be passed as parameters as in preRead
</p><div class="fullcomment"><div class="comment cmt"><p>Runs operations before writing to <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
Note: As the transformed SubFeed doesnt yet exist in Action.preWrite, no partition values can be passed as parameters as in preRead
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileDataObject#prepare" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="prepare(implicitsession:org.apache.spark.sql.SparkSession):Unit"></a><a id="prepare(SparkSession):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#prepare(implicitsession:org.apache.spark.sql.SparkSession):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">prepare</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Prepare &amp; test <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>'s prerequisits</p><div class="fullcomment"><div class="comment cmt"><p>Prepare &amp; test <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>'s prerequisits</p><p>This runs during the &quot;prepare&quot; operation of the DAG.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>FileDataObject → <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject#relativizePath" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="relativizePath(path:String):String"></a><a id="relativizePath(String):String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#relativizePath(path:String):String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">relativizePath</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <p class="shortcomment cmt">Make a given path relative to this DataObjects base path
</p><div class="fullcomment"><div class="comment cmt"><p>Make a given path relative to this DataObjects base path
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>HadoopFileDataObject → FileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#saveMode" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveMode:io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode"></a><a id="saveMode:SDLSaveMode"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#saveMode:io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">saveMode</span><span class="result">: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a></span>
      </span>
      
      <p class="shortcomment cmt">Overwrite or Append new data.</p><div class="fullcomment"><div class="comment cmt"><p>Overwrite or Append new data.
When writing partitioned data, this applies only to partitions concerned.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#schema" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="schema:Option[org.apache.spark.sql.types.StructType]"></a><a id="schema:Option[StructType]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#schema:Option[org.apache.spark.sql.types.StructType]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">schema</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>]</span>
      </span>
      
      <p class="shortcomment cmt">An optional <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> user-defined schema definition.</p><div class="fullcomment"><div class="comment cmt"><p>An optional <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> user-defined schema definition.</p><p>Some <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s support optional schema inference.
Specifying this attribute disables automatic schema inference. When the wrapped data source contains a source
schema, this <code>schema</code> attribute is ignored.</p><p>Note: This is only used by the functionality defined in <span class="extype" name="CanCreateDataFrame">CanCreateDataFrame</span>, that is,
when reading Spark data frames from the underlying data container.
<span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s that bypass Spark data frames ignore the <code>schema</code> attribute
if it is defined.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → UserDefinedSchema</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#schemaMin" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="schemaMin:Option[org.apache.spark.sql.types.StructType]"></a><a id="schemaMin:Option[StructType]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#schemaMin:Option[org.apache.spark.sql.types.StructType]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">schemaMin</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>]</span>
      </span>
      
      <p class="shortcomment cmt">An optional, minimal schema that a <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> schema must have to pass schema validation.</p><div class="fullcomment"><div class="comment cmt"><p>An optional, minimal schema that a <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> schema must have to pass schema validation.</p><p>The schema validation semantics are:
- Schema A is valid in respect to a minimal schema B when B is a subset of A. This means: the whole column set of B is contained in the column set of A.</p><ul><li>A column of B is contained in A when A contains a column with equal name and data type.</li><li>Column order is ignored.</li><li>Column nullability is ignored.</li><li>Duplicate columns in terms of name and data type are eliminated (set semantics).</li></ul><p>Note: This is only used by the functionality defined in <span class="extype" name="CanCreateDataFrame">CanCreateDataFrame</span> and <span class="extype" name="CanWriteDataFrame">CanWriteDataFrame</span>, that is,
when reading or writing Spark data frames from/to the underlying data container.
<span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s that bypass Spark data frames ignore the <code>schemaMin</code> attribute
if it is defined.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SchemaValidation</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileDataObject#separator" visbl="prt" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="separator:Char"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#separator:Char" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">separator</span><span class="result">: <span class="extype" name="scala.Char">Char</span></span>
      </span>
      
      <p class="shortcomment cmt">default separator for paths
</p><div class="fullcomment"><div class="comment cmt"><p>default separator for paths
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>FileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject#sparkRepartition" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sparkRepartition:Option[io.smartdatalake.util.hdfs.SparkRepartitionDef]"></a><a id="sparkRepartition:Option[SparkRepartitionDef]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#sparkRepartition:Option[io.smartdatalake.util.hdfs.SparkRepartitionDef]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sparkRepartition</span><span class="result">: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>]</span>
      </span>
      
      <p class="shortcomment cmt">Definition of repartition operation before writing DataFrame with Spark to Hadoop.</p><div class="fullcomment"><div class="comment cmt"><p>Definition of repartition operation before writing DataFrame with Spark to Hadoop.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject">ParquetFileDataObject</a> → SparkFileDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame#streamingOptions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="streamingOptions:Map[String,String]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#streamingOptions:Map[String,String]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">streamingOptions</span><span class="result">: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>CanWriteDataFrame</dd></dl></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a><a id="synchronized[T0](⇒T0):T0"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObject#toStringShort" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toStringShort:String"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#toStringShort:String" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toStringShort</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.FileRefDataObject#translateFileRefs" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="translateFileRefs(fileRefs:Seq[io.smartdatalake.workflow.dataobject.FileRef])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Seq[io.smartdatalake.workflow.dataobject.FileRef]"></a><a id="translateFileRefs(Seq[FileRef])(SparkSession,ActionPipelineContext):Seq[FileRef]"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#translateFileRefs(fileRefs:Seq[io.smartdatalake.workflow.dataobject.FileRef])(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Seq[io.smartdatalake.workflow.dataobject.FileRef]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">translateFileRefs</span><span class="params">(<span name="fileRefs">fileRefs: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="io.smartdatalake.workflow.dataobject.FileRef">FileRef</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="io.smartdatalake.workflow.dataobject.FileRef">FileRef</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Given some <span class="extype" name="FileRef">FileRef</span>s for another <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>, translate the paths to the root path of this <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
</p><div class="fullcomment"><div class="comment cmt"><p>Given some <span class="extype" name="FileRef">FileRef</span>s for another <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>, translate the paths to the root path of this <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd>FileRefDataObject</dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SchemaValidation#validateSchema" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="validateSchema(df:org.apache.spark.sql.DataFrame,schemaExpected:org.apache.spark.sql.types.StructType,role:String):Unit"></a><a id="validateSchema(DataFrame,StructType,String):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#validateSchema(df:org.apache.spark.sql.DataFrame,schemaExpected:org.apache.spark.sql.types.StructType,role:String):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">validateSchema</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="schemaExpected">schemaExpected: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>, <span name="role">role: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Validate the schema of a given Spark Data Frame <code>df</code> against a given expected schema.</p><div class="fullcomment"><div class="comment cmt"><p>Validate the schema of a given Spark Data Frame <code>df</code> against a given expected schema.
</p></div><dl class="paramcmts block"><dt class="param">df</dt><dd class="cmt"><p>The data frame to validate.</p></dd><dt class="param">schemaExpected</dt><dd class="cmt"><p>The expected schema to validate against.</p></dd><dt class="param">role</dt><dd class="cmt"><p>role used in exception message. Set to read or write.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>SchemaValidation</dd><dt>Exceptions thrown</dt><dd><span class="cmt"><p><span class="extype" name="SchemaViolationException"><code>SchemaViolationException</code></span> is the <code>schemaMin</code> does not validate.</p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CanHandlePartitions#validateSchemaHasPartitionCols" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="validateSchemaHasPartitionCols(df:org.apache.spark.sql.DataFrame,role:String):Unit"></a><a id="validateSchemaHasPartitionCols(DataFrame,String):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#validateSchemaHasPartitionCols(df:org.apache.spark.sql.DataFrame,role:String):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">validateSchemaHasPartitionCols</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="role">role: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Validate the schema of a given Spark Data Frame <code>df</code> that it contains the specified partition columns
</p><div class="fullcomment"><div class="comment cmt"><p>Validate the schema of a given Spark Data Frame <code>df</code> that it contains the specified partition columns
</p></div><dl class="paramcmts block"><dt class="param">df</dt><dd class="cmt"><p>The data frame to validate.</p></dd><dt class="param">role</dt><dd class="cmt"><p>role used in exception message. Set to read or write.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></dd><dt>Exceptions thrown</dt><dd><span class="cmt"><p><span class="extype" name="SchemaViolationException"><code>SchemaViolationException</code></span> if the partitions columns are not included.</p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SchemaValidation#validateSchemaMin" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="validateSchemaMin(df:org.apache.spark.sql.DataFrame,role:String):Unit"></a><a id="validateSchemaMin(DataFrame,String):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#validateSchemaMin(df:org.apache.spark.sql.DataFrame,role:String):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">validateSchemaMin</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="role">role: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Validate the schema of a given Spark Data Frame <code>df</code> against <code>schemaMin</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Validate the schema of a given Spark Data Frame <code>df</code> against <code>schemaMin</code>.
</p></div><dl class="paramcmts block"><dt class="param">df</dt><dd class="cmt"><p>The data frame to validate.</p></dd><dt class="param">role</dt><dd class="cmt"><p>role used in exception message. Set to read or write.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>SchemaValidation</dd><dt>Exceptions thrown</dt><dd><span class="cmt"><p><span class="extype" name="SchemaViolationException"><code>SchemaViolationException</code></span> is the <code>schemaMin</code> does not validate.</p></span></dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#wait():Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a><a id="wait(Long,Int):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a><a id="wait(Long):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#wait(x$1:Long):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
                <span class="name">@native</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SparkFileDataObject#writeDataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="writeDataFrame(df:org.apache.spark.sql.DataFrame,partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues],isRecursiveInput:Boolean)(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit"></a><a id="writeDataFrame(DataFrame,Seq[PartitionValues],Boolean)(SparkSession,ActionPipelineContext):Unit"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#writeDataFrame(df:org.apache.spark.sql.DataFrame,partitionValues:Seq[io.smartdatalake.util.hdfs.PartitionValues],isRecursiveInput:Boolean)(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):Unit" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">writeDataFrame</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="partitionValues">partitionValues: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="../../util/hdfs/PartitionValues.html" class="extype" name="io.smartdatalake.util.hdfs.PartitionValues">PartitionValues</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="isRecursiveInput">isRecursiveInput: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">Writes the provided <span class="extype" name="DataFrame">DataFrame</span> to the filesystem.</p><div class="fullcomment"><div class="comment cmt"><p>Writes the provided <span class="extype" name="DataFrame">DataFrame</span> to the filesystem.</p><p>The <code>partitionValues</code> attribute is used to partition the output by the given columns on the file system.
</p></div><dl class="paramcmts block"><dt class="param">df</dt><dd class="cmt"><p>the <span class="extype" name="DataFrame">DataFrame</span> to write to the file system.</p></dd><dt class="param">partitionValues</dt><dd class="cmt"><p>The partition layout to write.</p></dd><dt class="param">session</dt><dd class="cmt"><p>the current <span class="extype" name="SparkSession">SparkSession</span>.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>SparkFileDataObject → CanWriteDataFrame</dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="DataFrameWriter.partitionBy">DataFrameWriter.partitionBy</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame#writeStreamingDataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="writeStreamingDataFrame(df:org.apache.spark.sql.DataFrame,trigger:org.apache.spark.sql.streaming.Trigger,options:Map[String,String],checkpointLocation:String,queryName:String,outputMode:org.apache.spark.sql.streaming.OutputMode)(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):org.apache.spark.sql.streaming.StreamingQuery"></a><a id="writeStreamingDataFrame(DataFrame,Trigger,Map[String,String],String,String,OutputMode)(SparkSession,ActionPipelineContext):StreamingQuery"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html#writeStreamingDataFrame(df:org.apache.spark.sql.DataFrame,trigger:org.apache.spark.sql.streaming.Trigger,options:Map[String,String],checkpointLocation:String,queryName:String,outputMode:org.apache.spark.sql.streaming.OutputMode)(implicitsession:org.apache.spark.sql.SparkSession,implicitcontext:io.smartdatalake.workflow.ActionPipelineContext):org.apache.spark.sql.streaming.StreamingQuery" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">writeStreamingDataFrame</span><span class="params">(<span name="df">df: <span class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</span></span>, <span name="trigger">trigger: <span class="extype" name="org.apache.spark.sql.streaming.Trigger">Trigger</span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="checkpointLocation">checkpointLocation: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="queryName">queryName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="outputMode">outputMode: <span class="extype" name="org.apache.spark.sql.streaming.OutputMode">OutputMode</span> = <span class="symbol">OutputMode.Append</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="session">session: <span class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</span></span>, <span name="context">context: <a href="../ActionPipelineContext.html" class="extype" name="io.smartdatalake.workflow.ActionPipelineContext">ActionPipelineContext</a></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.streaming.StreamingQuery">StreamingQuery</span></span>
      </span>
      
      <p class="shortcomment cmt">Write Spark structured streaming DataFrame
The default implementation uses foreachBatch and this traits writeDataFrame method to write the DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Write Spark structured streaming DataFrame
The default implementation uses foreachBatch and this traits writeDataFrame method to write the DataFrame.
Some DataObjects will override this with specific implementations (Kafka).
</p></div><dl class="paramcmts block"><dt class="param">df</dt><dd class="cmt"><p>The Streaming DataFrame to write</p></dd><dt class="param">trigger</dt><dd class="cmt"><p>Trigger frequency for stream</p></dd><dt class="param">checkpointLocation</dt><dd class="cmt"><p>location for checkpoints of streaming query</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd>CanWriteDataFrame</dd></dl></div>
    </li>
              </ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="scala.Product">
              <h3>Inherited from <span class="extype" name="scala.Product">Product</span></h3>
            </div><div class="parent" name="scala.Equals">
              <h3>Inherited from <span class="extype" name="scala.Equals">Equals</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">SparkFileDataObjectWithEmbeddedSchema</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.SchemaValidation">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.SchemaValidation">SchemaValidation</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.UserDefinedSchema">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.UserDefinedSchema">UserDefinedSchema</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanCreateStreamingDataFrame">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateStreamingDataFrame">CanCreateStreamingDataFrame</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.HadoopFileDataObject">HadoopFileDataObject</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream">CanCreateOutputStream</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">CanCreateInputStream</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">FileRefDataObject</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.FileDataObject">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.workflow.dataobject.FileDataObject">FileDataObject</span></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">
              <h3>Inherited from <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.dataobject.DataObject">
              <h3>Inherited from <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a></h3>
            </div><div class="parent" name="io.smartdatalake.workflow.AtlasExportable">
              <h3>Inherited from <a href="../AtlasExportable.html" class="extype" name="io.smartdatalake.workflow.AtlasExportable">AtlasExportable</a></h3>
            </div><div class="parent" name="io.smartdatalake.util.misc.SmartDataLakeLogger">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span></h3>
            </div><div class="parent" name="io.smartdatalake.config.ParsableFromConfig">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>]</h3>
            </div><div class="parent" name="io.smartdatalake.config.SdlConfigObject">
              <h3>Inherited from <span class="extype" name="io.smartdatalake.config.SdlConfigObject">SdlConfigObject</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
    </body>
          </div>
        </div>
      </div>
    </body>
      </html>
