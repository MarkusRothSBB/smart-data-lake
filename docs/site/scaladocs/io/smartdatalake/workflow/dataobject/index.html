<!DOCTYPE html >
<html>
        <head>
          <meta http-equiv="X-UA-Compatible" content="IE=edge" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
          <title>sdl-core 2.0.4 API  - io.smartdatalake.workflow.dataobject</title>
          <meta name="description" content="sdl - core 2.0.4 API - io.smartdatalake.workflow.dataobject" />
          <meta name="keywords" content="sdl core 2.0.4 API io.smartdatalake.workflow.dataobject" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      
      <link href="../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../lib/jquery.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.panzoom.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.mousewheel.min.js"></script>
      <script type="text/javascript" src="../../../../lib/index.js"></script>
      <script type="text/javascript" src="../../../../index.js"></script>
      <script type="text/javascript" src="../../../../lib/scheduler.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      
      <script type="text/javascript">
        /* this variable can be used by the JS to determine the path to the root document */
        var toRoot = '../../../../';
      </script>
    
        </head>
        <body>
      <div id="search">
        <span id="doc-title">sdl-core 2.0.4 API<span id="doc-version"></span></span>
        <span class="close-results"><span class="left">&lt;</span> Back</span>
        <div id="textfilter">
          <span class="input">
            <input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/" />
            <i class="clear material-icons"></i>
            <i id="search-icon" class="material-icons"></i>
          </span>
        </div>
    </div>
      <div id="search-results">
        <div id="search-progress">
          <div id="progress-fill"></div>
        </div>
        <div id="results-content">
          <div id="entity-results"></div>
          <div id="member-results"></div>
        </div>
      </div>
      <div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;">
        <div id="content-container" style="-webkit-overflow-scrolling: touch;">
          <div id="subpackage-spacer">
            <div id="packages">
              <h1>Packages</h1>
              <ul>
                <li name="_root_.root" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="_root_"></a><a id="root:_root_"></a>
      <span class="permalink">
      <a href="../../../../index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../index.html"><span class="name">root</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="_root_.io" visbl="pub" class="indented1 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="io"></a><a id="io:io"></a>
      <span class="permalink">
      <a href="../../../../io/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../index.html"><span class="name">io</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="io.smartdatalake" visbl="pub" class="indented2 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="smartdatalake"></a><a id="smartdatalake:smartdatalake"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../index.html"><span class="name">smartdatalake</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../index.html" class="extype" name="io">io</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow" visbl="pub" class="indented3 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="workflow"></a><a id="workflow:workflow"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../index.html"><span class="name">workflow</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../index.html" class="extype" name="io.smartdatalake">smartdatalake</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.action" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="action"></a><a id="action:action"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/action/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../action/index.html"><span class="name">action</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.connection" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="connection"></a><a id="connection:connection"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/connection/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../connection/index.html"><span class="name">connection</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject" visbl="pub" class="indented4 current" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="dataobject"></a><a id="dataobject:dataobject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">dataobject</span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a></dd></dl></div>
    </li><li class="current-entities indented4">
                        <a class="object" href="AccessTableDataObject$.html" title=""></a>
                        <a class="class" href="AccessTableDataObject.html" title="DataObject of type JDBC / Access."></a>
                        <a href="AccessTableDataObject.html" title="DataObject of type JDBC / Access.">AccessTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ActionsExporterDataObject$.html" title=""></a>
                        <a class="class" href="ActionsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all io.smartdatalake.workflow.action.Actions that are registered in the current InstanceRegistry."></a>
                        <a href="ActionsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all io.smartdatalake.workflow.action.Actions that are registered in the current InstanceRegistry.">ActionsExporterDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="AvroFileDataObject$.html" title=""></a>
                        <a class="class" href="AvroFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Avro data source."></a>
                        <a href="AvroFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Avro data source.">AvroFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="CanHandlePartitions.html" title="A trait to be implemented by DataObjects which store partitioned data"></a>
                        <a href="CanHandlePartitions.html" title="A trait to be implemented by DataObjects which store partitioned data">CanHandlePartitions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ConnectionTestException.html" title=""></a>
                        <a href="ConnectionTestException.html" title="">ConnectionTestException</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CsvFileDataObject$.html" title=""></a>
                        <a class="class" href="CsvFileDataObject.html" title="A DataObject backed by a comma-separated value (CSV) data source."></a>
                        <a href="CsvFileDataObject.html" title="A DataObject backed by a comma-separated value (CSV) data source.">CsvFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CustomDfDataObject$.html" title=""></a>
                        <a class="class" href="CustomDfDataObject.html" title="Generic DataObject containing a config object."></a>
                        <a href="CustomDfDataObject.html" title="Generic DataObject containing a config object.">CustomDfDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="CustomFileDataObject$.html" title=""></a>
                        <a class="class" href="CustomFileDataObject.html" title=""></a>
                        <a href="CustomFileDataObject.html" title="">CustomFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="DataObject.html" title="This is the root trait for every DataObject."></a>
                        <a href="DataObject.html" title="This is the root trait for every DataObject.">DataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataObjectMetadata.html" title="Additional metadata for a DataObject"></a>
                        <a href="DataObjectMetadata.html" title="Additional metadata for a DataObject">DataObjectMetadata</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="DataObjectsExporterDataObject$.html" title=""></a>
                        <a class="class" href="DataObjectsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all DataObjects that are registered in the current InstanceRegistry."></a>
                        <a href="DataObjectsExporterDataObject.html" title="Exports a util DataFrame that contains properties and metadata extracted from all DataObjects that are registered in the current InstanceRegistry.">DataObjectsExporterDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ExcelFileDataObject$.html" title=""></a>
                        <a class="class" href="ExcelFileDataObject.html" title="A DataObject backed by an Microsoft Excel data source."></a>
                        <a href="ExcelFileDataObject.html" title="A DataObject backed by an Microsoft Excel data source.">ExcelFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ExcelOptions.html" title="Options passed to org.apache.spark.sql.DataFrameReader and org.apache.spark.sql.DataFrameWriter for reading and writing Microsoft Excel files."></a>
                        <a href="ExcelOptions.html" title="Options passed to org.apache.spark.sql.DataFrameReader and org.apache.spark.sql.DataFrameWriter for reading and writing Microsoft Excel files.">ExcelOptions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ForeignKey.html" title="Foreign key definition"></a>
                        <a href="ForeignKey.html" title="Foreign key definition">ForeignKey</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="HiveTableDataObject$.html" title=""></a>
                        <a class="class" href="HiveTableDataObject.html" title="DataObject of type Hive."></a>
                        <a href="HiveTableDataObject.html" title="DataObject of type Hive.">HiveTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="HttpProxyConfig.html" title=""></a>
                        <a href="HttpProxyConfig.html" title="">HttpProxyConfig</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="HttpTimeoutConfig.html" title=""></a>
                        <a href="HttpTimeoutConfig.html" title="">HttpTimeoutConfig</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="JdbcTableDataObject$.html" title=""></a>
                        <a class="class" href="JdbcTableDataObject.html" title="DataObject of type JDBC."></a>
                        <a href="JdbcTableDataObject.html" title="DataObject of type JDBC.">JdbcTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="JsonFileDataObject$.html" title=""></a>
                        <a class="class" href="JsonFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by a JSON data source."></a>
                        <a href="JsonFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by a JSON data source.">JsonFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="PKViolatorsDataObject$.html" title=""></a>
                        <a class="class" href="PKViolatorsDataObject.html" title="Checks for Primary Key violations for all DataObjects with Primary Keys defined that are registered in the current InstanceRegistry."></a>
                        <a href="PKViolatorsDataObject.html" title="Checks for Primary Key violations for all DataObjects with Primary Keys defined that are registered in the current InstanceRegistry.">PKViolatorsDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="ParquetFileDataObject$.html" title=""></a>
                        <a class="class" href="ParquetFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Apache Hive data source."></a>
                        <a href="ParquetFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Apache Hive data source.">ParquetFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="RawFileDataObject$.html" title=""></a>
                        <a class="class" href="RawFileDataObject.html" title="DataObject of type raw for files with unknown content."></a>
                        <a href="RawFileDataObject.html" title="DataObject of type raw for files with unknown content.">RawFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SFtpFileRefDataObject$.html" title=""></a>
                        <a class="class" href="SFtpFileRefDataObject.html" title="Connects to SFtp files Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot; The following authentication mechanisms are supported -&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server."></a>
                        <a href="SFtpFileRefDataObject.html" title="Connects to SFtp files Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot; The following authentication mechanisms are supported -&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server.">SFtpFileRefDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Table.html" title="Table attributes"></a>
                        <a href="Table.html" title="Table attributes">Table</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="TickTockHiveTableDataObject$.html" title=""></a>
                        <a class="class" href="TickTockHiveTableDataObject.html" title=""></a>
                        <a href="TickTockHiveTableDataObject.html" title="">TickTockHiveTableDataObject</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="WebserviceFileDataObject$.html" title=""></a>
                        <a class="class" href="WebserviceFileDataObject.html" title="DataObject to call webservice and return response as InputStream This is implemented as FileRefDataObject because the response is treated as some file content."></a>
                        <a href="WebserviceFileDataObject.html" title="DataObject to call webservice and return response as InputStream This is implemented as FileRefDataObject because the response is treated as some file content.">WebserviceFileDataObject</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="WebservicePartitionDefinition.html" title=""></a>
                        <a href="WebservicePartitionDefinition.html" title="">WebservicePartitionDefinition</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="XmlFileDataObject$.html" title=""></a>
                        <a class="class" href="XmlFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an XML data source."></a>
                        <a href="XmlFileDataObject.html" title="A io.smartdatalake.workflow.dataobject.DataObject backed by an XML data source.">XmlFileDataObject</a>
                      </li>
              </ul>
            </div>
          </div>
          <div id="content">
            <body class="package value">
      <div id="definition">
        <div class="big-circle package">p</div>
        <p id="owner"><a href="../../../index.html" class="extype" name="io">io</a>.<a href="../../index.html" class="extype" name="io.smartdatalake">smartdatalake</a>.<a href="../index.html" class="extype" name="io.smartdatalake.workflow">workflow</a></p>
        <h1>dataobject<span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span></h1>
        
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">dataobject</span>
      </span>
      </h4>

      
          <div id="comment" class="fullcommenttop"></div>
        

      <div id="mbrsel">
        <div class="toggle"></div>
        <div id="memberfilter">
          <i class="material-icons arrow"></i>
          <span class="input">
            <input id="mbrsel-input" placeholder="Filter all members" type="text" accesskey="/" />
          </span>
          <i class="clear material-icons"></i>
        </div>
        <div id="filterby">
          <div id="order">
            <span class="filtertype">Ordering</span>
            <ol>
              
              <li class="alpha in"><span>Alphabetic</span></li>
              
            </ol>
          </div>
          
          <div id="visbl">
              <span class="filtertype">Visibility</span>
              <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
            </div>
        </div>
      </div>

      <div id="template">
        <div id="allMembers">
        

        <div id="types" class="types members">
              <h3>Type Members</h3>
              <ol><li name="io.smartdatalake.workflow.dataobject.AccessTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="AccessTableDataObjectextendsTableDataObjectwithProductwithSerializable"></a><a id="AccessTableDataObject:AccessTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/AccessTableDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="DataObject of type JDBC / Access." href="AccessTableDataObject.html"><span class="name">AccessTableDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="table">table: <a href="Table.html" class="extype" name="io.smartdatalake.workflow.dataobject.Table">Table</a></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.TableDataObject">TableDataObject</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt"><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type JDBC / Access.</p><div class="fullcomment"><div class="comment cmt"><p><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type JDBC / Access.
Provides access to a Access DB to an Action. The functionality is handled seperately from <a href="JdbcTableDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.JdbcTableDataObject">JdbcTableDataObject</a>
to avoid problems with net.ucanaccess.jdbc.UcanaccessDriver
</p></div></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ActionsExporterDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ActionsExporterDataObjectextendsDataObjectwithCanCreateDataFramewithParsableFromConfig[io.smartdatalake.workflow.dataobject.ActionsExporterDataObject]withProductwithSerializable"></a><a id="ActionsExporterDataObject:ActionsExporterDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ActionsExporterDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Exports a util DataFrame that contains properties and metadata extracted from all io.smartdatalake.workflow.action.Actions that are registered in the current InstanceRegistry." href="ActionsExporterDataObject.html"><span class="name">ActionsExporterDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="config">config: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="ActionsExporterDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.ActionsExporterDataObject">ActionsExporterDataObject</a>] with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Exports a util <span class="extype" name="DataFrame">DataFrame</span> that contains properties and metadata extracted from all <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s
that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p><div class="fullcomment"><div class="comment cmt"><p>Exports a util <span class="extype" name="DataFrame">DataFrame</span> that contains properties and metadata extracted from all <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s
that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p><p>Alternatively, it can export the properties and metadata of all <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s defined in config files. For this, the
configuration &quot;config&quot; has to be set to the location of the config.</p><p>Example:</p><pre>dataObjects = {
 ...
 actions-exporter {
   <span class="kw">type</span> = ActionsExporterDataObject
   config = path/to/myconfiguration.conf
 }
 ...
}</pre><p>The config value can point to a configuration file or a directory containing configuration files.
</p></div><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p>Refer to <span class="extype" name="ConfigLoader.loadConfigFromFilesystem()">ConfigLoader.loadConfigFromFilesystem()</span> for details about the configuration loading.</p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.AvroFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="AvroFileDataObjectextendsSparkFileDataObjectWithEmbeddedSchemawithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="AvroFileDataObject:AvroFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/AvroFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Avro data source." href="AvroFileDataObject.html"><span class="name">AvroFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="avroOptions">avroOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">SparkFileDataObjectWithEmbeddedSchema</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an Avro data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an Avro data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on Avro formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively. The reader and writer implementations are provided by
the <a href="https://github.com/databricks/spark-avro" target="_blank">databricks spark-avro</a> project.
</p></div><dl class="paramcmts block"><dt class="param">avroOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and
                   <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional schema for the spark data frame to be validated on read and write. Note: Existing Avro files
              contain a source schema. Therefore, this schema is ignored when reading from existing Avro files.
              As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CanHandlePartitions" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="CanHandlePartitionsextendsAnyRef"></a><a id="CanHandlePartitions:CanHandlePartitions"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CanHandlePartitions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="A trait to be implemented by DataObjects which store partitioned data" href="CanHandlePartitions.html"><span class="name">CanHandlePartitions</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">A trait to be implemented by DataObjects which store partitioned data
</p><div class="fullcomment"><div class="comment cmt"><p>A trait to be implemented by DataObjects which store partitioned data
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ConnectionTestException" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="ConnectionTestExceptionextendsRuntimeExceptionwithProductwithSerializable"></a><a id="ConnectionTestException:ConnectionTestException"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ConnectionTestException.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="ConnectionTestException.html"><span class="name">ConnectionTestException</span></a><span class="params">(<span name="msg">msg: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="ex">ex: <a href="../../../../scala/index.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result"> extends <a href="../../../../scala/index.html#RuntimeException=RuntimeException" class="extmbr" name="scala.RuntimeException">RuntimeException</a> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.CsvFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="CsvFileDataObjectextendsSparkFileDataObjectwithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="CsvFileDataObject:CsvFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CsvFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A DataObject backed by a comma-separated value (CSV) data source." href="CsvFileDataObject.html"><span class="name">CsvFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="csvOptions">csvOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Map()</a></span></span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="dateColumnType">dateColumnType: <a href="../../definitions/DateColumnType$.html#DateColumnType=io.smartdatalake.definitions.DateColumnType.Value" class="extmbr" name="io.smartdatalake.definitions.DateColumnType.DateColumnType">DateColumnType</a> = <span class="symbol"><span class="name"><a href="../../../index.html">DateColumnType.Date</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> backed by a comma-separated value (CSV) data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> backed by a comma-separated value (CSV) data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on CSV formatted files.</p><p>CSV reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively.</p><p>Read Schema specifications:</p><p>If a data object schema is not defined via the <code>schema</code> attribute (default) and <code>inferSchema</code> option is
disabled (default) in <code>csvOptions</code>, then all column types are set to String and the first row of the CSV file is read
to determine the column names and the number of fields.</p><p>If the <code>header</code> option is disabled (default) in <code>csvOptions</code>, then the header is defined as &quot;_c#&quot; for each column
where &quot;#&quot; is the column index.
Otherwise the first row of the CSV file is not included in the DataFrame content and its entries
are used as the column names for the schema.</p><p>If a data object schema is not defined via the <code>schema</code> attribute and <code>inferSchema</code> is enabled in <code>csvOptions</code>, then
the <code>samplingRatio</code> (default: 1.0) option in <code>csvOptions</code> is used to extract a sample from the CSV file in order to
determine the input schema automatically.
</p></div><dl class="paramcmts block"><dt class="param">csvOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional data object schema. If defined, any automatic schema inference is avoided. As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">dateColumnType</dt><dd class="cmt"><p>Specifies the string format used for writing date typed data.</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>This data object sets the following default values for <code>csvOptions</code>: delimiter = &quot;|&quot;, quote = null, header = false, and inferSchema = false.
      All other <code>csvOption</code> default to the values defined by Apache Spark.</p></span></dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CustomDfDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="CustomDfDataObjectextendsDataObjectwithCanCreateDataFramewithSchemaValidationwithProductwithSerializable"></a><a id="CustomDfDataObject:CustomDfDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CustomDfDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Generic DataObject containing a config object." href="CustomDfDataObject.html"><span class="name">CustomDfDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="creator">creator: <a href="../action/customlogic/CustomDfCreatorConfig.html" class="extype" name="io.smartdatalake.workflow.action.customlogic.CustomDfCreatorConfig">CustomDfCreatorConfig</a></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.SchemaValidation">SchemaValidation</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Generic <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> containing a config object.</p><div class="fullcomment"><div class="comment cmt"><p>Generic <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> containing a config object.
E.g. used to implement a CustomAction that reads a Webservice.
</p></div></div>
    </li><li name="io.smartdatalake.workflow.dataobject.CustomFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="CustomFileDataObjectextendsDataObjectwithFileRefDataObjectwithCanCreateInputStreamwithProductwithSerializable"></a><a id="CustomFileDataObject:CustomFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CustomFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="CustomFileDataObject.html"><span class="name">CustomFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="creator">creator: <a href="../action/customlogic/CustomFileCreatorConfig.html" class="extype" name="io.smartdatalake.workflow.action.customlogic.CustomFileCreatorConfig">CustomFileCreatorConfig</a></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> with <span class="extype" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">FileRefDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">CanCreateInputStream</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.DataObject" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="DataObjectextendsSdlConfigObjectwithParsableFromConfig[io.smartdatalake.workflow.dataobject.DataObject]withSmartDataLakeLoggerwithAtlasExportable"></a><a id="DataObject:DataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/DataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="This is the root trait for every DataObject." href="DataObject.html"><span class="name">DataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.SdlConfigObject">SdlConfigObject</span> with <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <a href="../AtlasExportable.html" class="extype" name="io.smartdatalake.workflow.AtlasExportable">AtlasExportable</a></span>
      </span>
      
      <p class="shortcomment cmt">This is the root trait for every DataObject.</p><div class="fullcomment"><div class="comment cmt"><p>This is the root trait for every DataObject.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObjectMetadata" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataObjectMetadataextendsProductwithSerializable"></a><a id="DataObjectMetadata:DataObjectMetadata"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/DataObjectMetadata.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Additional metadata for a DataObject" href="DataObjectMetadata.html"><span class="name">DataObjectMetadata</span></a><span class="params">(<span name="name">name: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="description">description: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="layer">layer: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="subjectArea">subjectArea: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="tags">tags: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Additional metadata for a DataObject</p><div class="fullcomment"><div class="comment cmt"><p>Additional metadata for a DataObject</p></div><dl class="paramcmts block"><dt class="param">name</dt><dd class="cmt"><p>Readable name of the DataObject</p></dd><dt class="param">description</dt><dd class="cmt"><p>Description of the content of the DataObject</p></dd><dt class="param">layer</dt><dd class="cmt"><p>Name of the layer this DataObject belongs to</p></dd><dt class="param">subjectArea</dt><dd class="cmt"><p>Name of the subject area this DataObject belongs to</p></dd><dt class="param">tags</dt><dd class="cmt"><p>Optional custom tags for this object</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.DataObjectsExporterDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataObjectsExporterDataObjectextendsDataObjectwithCanCreateDataFramewithParsableFromConfig[io.smartdatalake.workflow.dataobject.DataObjectsExporterDataObject]withProductwithSerializable"></a><a id="DataObjectsExporterDataObject:DataObjectsExporterDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/DataObjectsExporterDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Exports a util DataFrame that contains properties and metadata extracted from all DataObjects that are registered in the current InstanceRegistry." href="DataObjectsExporterDataObject.html"><span class="name">DataObjectsExporterDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="config">config: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="DataObjectsExporterDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectsExporterDataObject">DataObjectsExporterDataObject</a>] with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Exports a util <span class="extype" name="DataFrame">DataFrame</span> that contains properties and metadata extracted from all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s
that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p><div class="fullcomment"><div class="comment cmt"><p>Exports a util <span class="extype" name="DataFrame">DataFrame</span> that contains properties and metadata extracted from all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s
that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p><p>Alternatively, it can export the properties and metadata of all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s defined in config files. For this, the
configuration &quot;config&quot; has to be set to the location of the config.</p><p>Example:</p><pre>```dataObjects = {
 ...
 dataobject-exporter {
   <span class="kw">type</span> = DataObjectsExporterDataObject
   config = path/to/myconfiguration.conf
 }
 ...
}</pre><p>The config value can point to a configuration file or a directory containing configuration files.
</p></div><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p>Refer to <span class="extype" name="ConfigLoader.loadConfigFromFilesystem()">ConfigLoader.loadConfigFromFilesystem()</span> for details about the configuration loading.</p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ExcelFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ExcelFileDataObjectextendsSparkFileDataObjectwithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="ExcelFileDataObject:ExcelFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ExcelFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A DataObject backed by an Microsoft Excel data source." href="ExcelFileDataObject.html"><span class="name">ExcelFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="excelOptions">excelOptions: <a href="ExcelOptions.html" class="extype" name="io.smartdatalake.workflow.dataobject.ExcelOptions">ExcelOptions</a> = <span class="symbol">ExcelOptions()</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="defval" name='<span class="name"><a href="../../../index.html">Some(SparkRepartitionDef(numberOfTasksPerPartition = 1))</a></span>'>...</span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> backed by an Microsoft Excel data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> backed by an Microsoft Excel data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on Microsoft Excel (.xslx) formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively. The reader and writer implementation is provided by the
<a href="https://github.com/crealytics/spark-excel" target="_blank">Crealytics spark-excel</a> project.</p><p>Read Schema:</p><p>When <code>useHeader</code> is set to true (default), the reader will use the first row of the Excel sheet as column names for
the schema and not include the first row as data values. Otherwise the column names are taken from the schema.
If the schema is not provided or inferred, then each column name is defined as &quot;_c#&quot; where &quot;#&quot; is the column index.</p><p>When a data object schema is provided, it is used as the schema for the DataFrame. Otherwise if <code>inferSchema</code> is
enabled (default), then the data types of the columns are inferred based on the first <code>excerptSize</code> rows
(excluding the first).
When no schema is provided and <code>inferSchema</code> is disabled, all columns are assumed to be of string type.
</p></div><dl class="paramcmts block"><dt class="param">excelOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional data object schema. If defined, any automatic schema inference is avoided. As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop. Default is numberOfTasksPerPartition = 1.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ExcelOptions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ExcelOptionsextendsProductwithSerializable"></a><a id="ExcelOptions:ExcelOptions"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ExcelOptions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Options passed to org.apache.spark.sql.DataFrameReader and org.apache.spark.sql.DataFrameWriter for reading and writing Microsoft Excel files." href="ExcelOptions.html"><span class="name">ExcelOptions</span></a><span class="params">(<span name="sheetName">sheetName: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="numLinesToSkip">numLinesToSkip: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Int">Int</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="startColumn">startColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="endColumn">endColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="rowLimit">rowLimit: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Int">Int</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="useHeader">useHeader: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">true</span></span>, <span name="treatEmptyValuesAsNulls">treatEmptyValuesAsNulls: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Boolean">Boolean</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Some(true)</a></span></span></span>, <span name="inferSchema">inferSchema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Boolean">Boolean</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Some(true)</a></span></span></span>, <span name="timestampFormat">timestampFormat: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Some(&quot;dd-MM-yyyy HH:mm:ss&quot;)</a></span></span></span>, <span name="dateFormat">dateFormat: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="maxRowsInMemory">maxRowsInMemory: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Int">Int</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="excerptSize">excerptSize: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Int">Int</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Options passed to <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> for
reading and writing Microsoft Excel files.</p><div class="fullcomment"><div class="comment cmt"><p>Options passed to <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> for
reading and writing Microsoft Excel files. Excel support is provided by the spark-excel project (see link below).
</p></div><dl class="paramcmts block"><dt class="param">sheetName</dt><dd class="cmt"><p>Optional name of the Excel Sheet to read from/write to.</p></dd><dt class="param">numLinesToSkip</dt><dd class="cmt"><p>Optional number of rows in the excel spreadsheet to skip before any data is read.
                      This option must not be set for writing.</p></dd><dt class="param">startColumn</dt><dd class="cmt"><p>Optional first column in the specified Excel Sheet to read from (as string, e.g B).
                   This option must not be set for writing.</p></dd><dt class="param">endColumn</dt><dd class="cmt"><p>Optional last column in the specified Excel Sheet to read from (as string, e.g. F).</p></dd><dt class="param">rowLimit</dt><dd class="cmt"><p>Optional limit of the number of rows being returned on read.
                This is applied after <code>numLinesToSkip</code>.</p></dd><dt class="param">useHeader</dt><dd class="cmt"><p>If <code>true</code>, the first row of the excel sheet specifies the column names (default: true).</p></dd><dt class="param">treatEmptyValuesAsNulls</dt><dd class="cmt"><p>Empty cells are parsed as <code>null</code> values (default: true).</p></dd><dt class="param">inferSchema</dt><dd class="cmt"><p>Infer the schema of the excel sheet automatically (default: true).</p></dd><dt class="param">timestampFormat</dt><dd class="cmt"><p>A format string specifying the format to use when writing timestamps (default: dd-MM-yyyy HH:mm:ss).</p></dd><dt class="param">dateFormat</dt><dd class="cmt"><p>A format string specifying the format to use when writing dates.</p></dd><dt class="param">maxRowsInMemory</dt><dd class="cmt"><p>The number of rows that are stored in memory.
                       If set, a streaming reader is used which can help with big files.</p></dd><dt class="param">excerptSize</dt><dd class="cmt"><p>Sample size for schema inference.</p></dd></dl><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p><a href="https://github.com/crealytics/spark-excel" target="_blank">https://github.com/crealytics/spark-excel</a></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ForeignKey" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ForeignKeyextendsProductwithSerializable"></a><a id="ForeignKey:ForeignKey"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ForeignKey.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Foreign key definition" href="ForeignKey.html"><span class="name">ForeignKey</span></a><span class="params">(<span name="db">db: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="columns">columns: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="name">name: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Foreign key definition
</p><div class="fullcomment"><div class="comment cmt"><p>Foreign key definition
</p></div><dl class="paramcmts block"><dt class="param">db</dt><dd class="cmt"><p>target database, if not defined it is assumed to be the same as the table owning the foreign key</p></dd><dt class="param">table</dt><dd class="cmt"><p>referenced target table name</p></dd><dt class="param">columns</dt><dd class="cmt"><p>mapping of source column(s) to referenced target table column(s)</p></dd><dt class="param">name</dt><dd class="cmt"><p>optional name for foreign key, e.g to depict it's role</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HiveTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="HiveTableDataObjectextendsTableDataObjectwithCanWriteDataFramewithCanHandlePartitionswithSmartDataLakeLoggerwithProductwithSerializable"></a><a id="HiveTableDataObject:HiveTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/HiveTableDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="DataObject of type Hive." href="HiveTableDataObject.html"><span class="name">HiveTableDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="analyzeTableAfterWrite">analyzeTableAfterWrite: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="dateColumnType">dateColumnType: <a href="../../definitions/DateColumnType$.html#DateColumnType=io.smartdatalake.definitions.DateColumnType.Value" class="extmbr" name="io.smartdatalake.definitions.DateColumnType.DateColumnType">DateColumnType</a> = <span class="symbol"><span class="name"><a href="../../../index.html">DateColumnType.Date</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="table">table: <a href="Table.html" class="extype" name="io.smartdatalake.workflow.dataobject.Table">Table</a></span>, <span name="numInitialHdfsPartitions">numInitialHdfsPartitions: <span class="extype" name="scala.Int">Int</span> = <span class="symbol">16</span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.TableDataObject">TableDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a> with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt"><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type Hive.</p><div class="fullcomment"><div class="comment cmt"><p><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type Hive.
Provides details to access Hive tables to an Action
</p></div><dl class="paramcmts block"><dt class="param">id</dt><dd class="cmt"><p>unique name of this data object</p></dd><dt class="param">path</dt><dd class="cmt"><p>hadoop directory for this table. If it doesn't contain scheme and authority, the connections pathPrefix is applied.
            If pathPrefix is not defined or doesn't define scheme and authority, default schema and authority is applied.
            If DataObject is only used for reading or if the HiveTable already exist, the path can be omitted.
            If the HiveTable already exists but with a different path, a warning is issued</p></dd><dt class="param">partitions</dt><dd class="cmt"><p>partition columns for this data object</p></dd><dt class="param">analyzeTableAfterWrite</dt><dd class="cmt"><p>enable compute statistics after writing data (default=false)</p></dd><dt class="param">dateColumnType</dt><dd class="cmt"><p>type of date column</p></dd><dt class="param">schemaMin</dt><dd class="cmt"><p>An optional, minimal schema that this DataObject must have to pass schema validation on reading and writing.</p></dd><dt class="param">table</dt><dd class="cmt"><p>hive table to be written by this output</p></dd><dt class="param">numInitialHdfsPartitions</dt><dd class="cmt"><p>number of files created when writing into an empty table (otherwise the number will be derived from the existing data)</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>spark <span class="extype" name="SaveMode">SaveMode</span> to use when writing files, default is &quot;overwrite&quot;</p></dd><dt class="param">acl</dt><dd class="cmt"><p>override connections permissions for files created tables hadoop directory with this connection</p></dd><dt class="param">connectionId</dt><dd class="cmt"><p>optional id of <a href="../connection/HiveTableConnection.html" class="extype" name="io.smartdatalake.workflow.connection.HiveTableConnection">io.smartdatalake.workflow.connection.HiveTableConnection</a></p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd><dt class="param">metadata</dt><dd class="cmt"><p>meta data</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.HttpProxyConfig" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="HttpProxyConfigextendsProductwithSerializable"></a><a id="HttpProxyConfig:HttpProxyConfig"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/HttpProxyConfig.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="HttpProxyConfig.html"><span class="name">HttpProxyConfig</span></a><span class="params">(<span name="host">host: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.HttpTimeoutConfig" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="HttpTimeoutConfigextendsProductwithSerializable"></a><a id="HttpTimeoutConfig:HttpTimeoutConfig"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/HttpTimeoutConfig.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="HttpTimeoutConfig.html"><span class="name">HttpTimeoutConfig</span></a><span class="params">(<span name="connectionTimeoutMs">connectionTimeoutMs: <span class="extype" name="scala.Int">Int</span></span>, <span name="readTimeoutMs">readTimeoutMs: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.JdbcTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="JdbcTableDataObjectextendsTransactionalSparkTableDataObjectwithCanHandlePartitionswithProductwithSerializable"></a><a id="JdbcTableDataObject:JdbcTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/JdbcTableDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="DataObject of type JDBC." href="JdbcTableDataObject.html"><span class="name">JdbcTableDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="createSql">createSql: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="preReadSql">preReadSql: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="postReadSql">postReadSql: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="preWriteSql">preWriteSql: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="postWriteSql">postWriteSql: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="table">table: <a href="Table.html" class="extype" name="io.smartdatalake.workflow.dataobject.Table">Table</a></span>, <span name="jdbcFetchSize">jdbcFetchSize: <span class="extype" name="scala.Int">Int</span> = <span class="symbol">1000</span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="connectionId">connectionId: <a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a></span>, <span name="jdbcOptions">jdbcOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Map()</a></span></span></span>, <span name="virtualPartitions">virtualPartitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.TransactionalSparkTableDataObject">TransactionalSparkTableDataObject</span> with <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt"><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type JDBC.</p><div class="fullcomment"><div class="comment cmt"><p><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> of type JDBC.
Provides details for an action to access tables in a database through JDBC.</p></div><dl class="paramcmts block"><dt class="param">id</dt><dd class="cmt"><p>unique name of this data object</p></dd><dt class="param">createSql</dt><dd class="cmt"><p>DDL-statement to be executed in prepare phase, using output jdbc connection</p></dd><dt class="param">preReadSql</dt><dd class="cmt"><p>SQL-statement to be executed in exec phase before reading input table, using input jdbc connection.
                  Use tokens with syntax %{&lt;spark sql expression&gt;} to substitute with values from <span class="extype" name="DefaultExpressionData">DefaultExpressionData</span>.</p></dd><dt class="param">postReadSql</dt><dd class="cmt"><p>SQL-statement to be executed in exec phase after reading input table and before action is finished, using input jdbc connection
                  Use tokens with syntax %{&lt;spark sql expression&gt;} to substitute with values from <span class="extype" name="DefaultExpressionData">DefaultExpressionData</span>.</p></dd><dt class="param">preWriteSql</dt><dd class="cmt"><p>SQL-statement to be executed in exec phase before writing output table, using output jdbc connection
                  Use tokens with syntax %{&lt;spark sql expression&gt;} to substitute with values from <span class="extype" name="DefaultExpressionData">DefaultExpressionData</span>.</p></dd><dt class="param">postWriteSql</dt><dd class="cmt"><p>SQL-statement to be executed in exec phase after writing output table, using output jdbc connection
                  Use tokens with syntax %{&lt;spark sql expression&gt;} to substitute with values from <span class="extype" name="DefaultExpressionData">DefaultExpressionData</span>.</p></dd><dt class="param">schemaMin</dt><dd class="cmt"><p>An optional, minimal schema that this DataObject must have to pass schema validation on reading and writing.</p></dd><dt class="param">table</dt><dd class="cmt"><p>The jdbc table to be read</p></dd><dt class="param">jdbcFetchSize</dt><dd class="cmt"><p>Number of rows to be fetched together by the Jdbc driver</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p><span class="extype" name="SDLSaveMode">SDLSaveMode</span> to use when writing table, default is &quot;Overwrite&quot;. Only &quot;Append&quot; and &quot;Overwrite&quot; supported.</p></dd><dt class="param">connectionId</dt><dd class="cmt"><p>Id of JdbcConnection configuration</p></dd><dt class="param">jdbcOptions</dt><dd class="cmt"><p>Any jdbc options according to <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html" target="_blank">https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html</a>.
                   Note that some options above set and override some of this options explicitly.</p></dd><dt class="param">virtualPartitions</dt><dd class="cmt"><p>Virtual partition columns. Note that this doesn't need to be the same as the database partition
                  columns for this table. But it is important that there is an index on these columns to efficiently
                  list existing &quot;partitions&quot;.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.JsonFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="JsonFileDataObjectextendsSparkFileDataObjectwithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="JsonFileDataObject:JsonFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/JsonFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A io.smartdatalake.workflow.dataobject.DataObject backed by a JSON data source." href="JsonFileDataObject.html"><span class="name">JsonFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="jsonOptions">jsonOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="stringify">stringify: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by a JSON data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by a JSON data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on JSON formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively.
</p></div><dl class="paramcmts block"><dt class="param">jsonOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and
                   <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional data object schema. If defined, any automatic schema inference is avoided. As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">stringify</dt><dd class="cmt"><p>Set the data type for all values to string.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>By default, the JSON option <code>multiline</code> is enabled.</p></span></dd><dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.PKViolatorsDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="PKViolatorsDataObjectextendsDataObjectwithCanCreateDataFramewithParsableFromConfig[io.smartdatalake.workflow.dataobject.PKViolatorsDataObject]withProductwithSerializable"></a><a id="PKViolatorsDataObject:PKViolatorsDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/PKViolatorsDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Checks for Primary Key violations for all DataObjects with Primary Keys defined that are registered in the current InstanceRegistry." href="PKViolatorsDataObject.html"><span class="name">PKViolatorsDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="config">config: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="flattenOutput">flattenOutput: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.config.ParsableFromConfig">ParsableFromConfig</span>[<a href="PKViolatorsDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.PKViolatorsDataObject">PKViolatorsDataObject</a>] with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Checks for Primary Key violations for all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s with Primary Keys defined that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.</p><div class="fullcomment"><div class="comment cmt"><p>Checks for Primary Key violations for all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s with Primary Keys defined that are registered in the current <span class="extype" name="InstanceRegistry">InstanceRegistry</span>.
Returns the list of Primary Key violations as a <span class="extype" name="DataFrame">DataFrame</span>.</p><p>Alternatively, it can check for Primary Key violations of all <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>s defined in config files. For this, the
configuration &quot;config&quot; has to be set to the location of the config.</p><p>Example:</p><pre>```dataObjects = {
 ...
 primarykey-violations {
   <span class="kw">type</span> = PKViolatorsDataObject
   config = path/to/myconfiguration.conf
 }
 ...
}</pre></div><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p>Refer to <span class="extype" name="ConfigLoader.loadConfigFromFilesystem()">ConfigLoader.loadConfigFromFilesystem()</span> for details about the configuration loading.</p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ParquetFileDataObjectextendsSparkFileDataObjectWithEmbeddedSchemawithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="ParquetFileDataObject:ParquetFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A io.smartdatalake.workflow.dataobject.DataObject backed by an Apache Hive data source." href="ParquetFileDataObject.html"><span class="name">ParquetFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="parquetOptions">parquetOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObjectWithEmbeddedSchema">SparkFileDataObjectWithEmbeddedSchema</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an Apache Hive data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an Apache Hive data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on Parquet formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively.
</p></div><dl class="paramcmts block"><dt class="param">id</dt><dd class="cmt"><p>unique name of this data object</p></dd><dt class="param">path</dt><dd class="cmt"><p>Hadoop directory where this data object reads/writes it's files.
            If it doesn't contain scheme and authority, the connections pathPrefix is applied. If pathPrefix is not
            defined or doesn't define scheme and authority, default schema and authority is applied.
            Optionally defined partitions are appended with hadoop standard partition layout to this path.
            Only files ending with *.parquet* are considered as data for this DataObject.</p></dd><dt class="param">partitions</dt><dd class="cmt"><p>partition columns for this data object</p></dd><dt class="param">parquetOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and
                      <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional schema for the spark data frame to be validated on read and write. Note: Existing Parquet files
              contain a source schema. Therefore, this schema is ignored when reading from existing Parquet files.
              As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>spark <span class="extype" name="SaveMode">SaveMode</span> to use when writing files, default is &quot;overwrite&quot;</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">acl</dt><dd class="cmt"><p>override connections permissions for files created with this connection</p></dd><dt class="param">connectionId</dt><dd class="cmt"><p>optional id of <a href="../connection/HadoopFileConnection.html" class="extype" name="io.smartdatalake.workflow.connection.HadoopFileConnection">io.smartdatalake.workflow.connection.HadoopFileConnection</a></p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd><dt class="param">metadata</dt><dd class="cmt"><p>Metadata describing this data object.</p></dd></dl><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.RawFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="RawFileDataObjectextendsSparkFileDataObjectwithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="RawFileDataObject:RawFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/RawFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="DataObject of type raw for files with unknown content." href="RawFileDataObject.html"><span class="name">RawFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="customFormat">customFormat: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Map()</a></span></span></span>, <span name="fileName">fileName: <span class="extype" name="scala.Predef.String">String</span> = <span class="symbol">&quot;*&quot;</span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">DataObject of type raw for files with unknown content.</p><div class="fullcomment"><div class="comment cmt"><p>DataObject of type raw for files with unknown content.
Provides details to an Action to access raw files.
By specifying format you can custom Spark data formats
</p></div><dl class="paramcmts block"><dt class="param">customFormat</dt><dd class="cmt"><p>Custom Spark data source format, e.g. binaryFile or text. Only needed if you want to read/write this DataObject with Spark.</p></dd><dt class="param">options</dt><dd class="cmt"><p>Options for custom Spark data source format. Only of use if you want to read/write this DataObject with Spark.</p></dd><dt class="param">fileName</dt><dd class="cmt"><p>Definition of fileName. This is concatenated with path and partition layout to search for files. Default is an asterix to match everything.</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>Overwrite or Append new data.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.SFtpFileRefDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SFtpFileRefDataObjectextendsFileRefDataObjectwithCanCreateInputStreamwithCanCreateOutputStreamwithSmartDataLakeLoggerwithProductwithSerializable"></a><a id="SFtpFileRefDataObject:SFtpFileRefDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/SFtpFileRefDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Connects to SFtp files Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot; The following authentication mechanisms are supported -&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server." href="SFtpFileRefDataObject.html"><span class="name">SFtpFileRefDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="connectionId">connectionId: <a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="partitionLayout">partitionLayout: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">FileRefDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">CanCreateInputStream</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream">CanCreateOutputStream</span> with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Connects to SFtp files
Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot;
The following authentication mechanisms are supported
-&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server.</p><div class="fullcomment"><div class="comment cmt"><p>Connects to SFtp files
Needs java library &quot;com.hieronymus % sshj % 0.21.1&quot;
The following authentication mechanisms are supported
-&gt; public/private-key: private key must be saved in ~/.ssh, public key must be registered on server.
-&gt; user/pwd authentication: user and password is taken from two variables set as parameters.
                            These variables could come from clear text (CLEAR), a file (FILE) or an environment variable (ENV)
</p></div><dl class="paramcmts block"><dt class="param">partitionLayout</dt><dd class="cmt"><p>partition layout defines how partition values can be extracted from the path.
                       Use &quot;%&lt;colname&gt;%&quot; as token to extract the value for a partition column.
                       With &quot;%&lt;colname:regex&gt;%&quot; a regex can be given to limit search. This is especially useful
                       if there is no char to delimit the last token from the rest of the path or also between
                       two tokens.</p></dd><dt class="param">saveMode</dt><dd class="cmt"><p>Overwrite or Append new data.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.Table" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="TableextendsProductwithSerializable"></a><a id="Table:Table"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/Table.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="Table attributes" href="Table.html"><span class="name">Table</span></a><span class="params">(<span name="db">db: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="name">name: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="query">query: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="primaryKey">primaryKey: <span class="extype" name="scala.Option">Option</span>[<a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="foreignKeys">foreignKeys: <span class="extype" name="scala.Option">Option</span>[<a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="ForeignKey.html" class="extype" name="io.smartdatalake.workflow.dataobject.ForeignKey">ForeignKey</a>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="options">options: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Table attributes
</p><div class="fullcomment"><div class="comment cmt"><p>Table attributes
</p></div><dl class="paramcmts block"><dt class="param">db</dt><dd class="cmt"><p>optional override of db defined by connection</p></dd><dt class="param">name</dt><dd class="cmt"><p>table name</p></dd><dt class="param">query</dt><dd class="cmt"><p>optional select query</p></dd><dt class="param">primaryKey</dt><dd class="cmt"><p>optional sequence of primary key columns</p></dd><dt class="param">foreignKeys</dt><dd class="cmt"><p>optional sequence of foreign key definitions.
                   This is used as metadata for a data catalog.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.TickTockHiveTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="TickTockHiveTableDataObjectextendsTransactionalSparkTableDataObjectwithCanHandlePartitionswithProductwithSerializable"></a><a id="TickTockHiveTableDataObject:TickTockHiveTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/TickTockHiveTableDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="TickTockHiveTableDataObject.html"><span class="name">TickTockHiveTableDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="analyzeTableAfterWrite">analyzeTableAfterWrite: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="dateColumnType">dateColumnType: <a href="../../definitions/DateColumnType$.html#DateColumnType=io.smartdatalake.definitions.DateColumnType.Value" class="extmbr" name="io.smartdatalake.definitions.DateColumnType.DateColumnType">DateColumnType</a> = <span class="symbol"><span class="name"><a href="../../../index.html">DateColumnType.Date</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="table">table: <a href="Table.html" class="extype" name="io.smartdatalake.workflow.dataobject.Table">Table</a></span>, <span name="numInitialHdfsPartitions">numInitialHdfsPartitions: <span class="extype" name="scala.Int">Int</span> = <span class="symbol">16</span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.TransactionalSparkTableDataObject">TransactionalSparkTableDataObject</span> with <a href="CanHandlePartitions.html" class="extype" name="io.smartdatalake.workflow.dataobject.CanHandlePartitions">CanHandlePartitions</a> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.WebserviceFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="WebserviceFileDataObjectextendsFileRefDataObjectwithCanCreateInputStreamwithCanCreateOutputStreamwithSmartDataLakeLoggerwithProductwithSerializable"></a><a id="WebserviceFileDataObject:WebserviceFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/WebserviceFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="DataObject to call webservice and return response as InputStream This is implemented as FileRefDataObject because the response is treated as some file content." href="WebserviceFileDataObject.html"><span class="name">WebserviceFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="additionalHeaders">additionalHeaders: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Map()</a></span></span></span>, <span name="timeouts">timeouts: <span class="extype" name="scala.Option">Option</span>[<a href="HttpTimeoutConfig.html" class="extype" name="io.smartdatalake.workflow.dataobject.HttpTimeoutConfig">HttpTimeoutConfig</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="readTimeoutMs">readTimeoutMs: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Int">Int</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="authMode">authMode: <span class="extype" name="scala.Option">Option</span>[<a href="../../definitions/AuthMode.html" class="extype" name="io.smartdatalake.definitions.AuthMode">AuthMode</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="mimeType">mimeType: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="writeMethod">writeMethod: <a href="../../util/webservice/WebserviceWriteMethod$.html#WebserviceWriteMethod=io.smartdatalake.util.webservice.WebserviceWriteMethod.Value" class="extmbr" name="io.smartdatalake.util.webservice.WebserviceWriteMethod.WebserviceWriteMethod">WebserviceWriteMethod</a> = <span class="symbol"><span class="name"><a href="../../../index.html">WebserviceWriteMethod.Post</a></span></span></span>, <span name="proxy">proxy: <span class="extype" name="scala.Option">Option</span>[<a href="HttpProxyConfig.html" class="extype" name="io.smartdatalake.workflow.dataobject.HttpProxyConfig">HttpProxyConfig</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="followRedirects">followRedirects: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="partitionDefs">partitionDefs: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<a href="WebservicePartitionDefinition.html" class="extype" name="io.smartdatalake.workflow.dataobject.WebservicePartitionDefinition">WebservicePartitionDefinition</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="partitionLayout">partitionLayout: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.FileRefDataObject">FileRefDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateInputStream">CanCreateInputStream</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateOutputStream">CanCreateOutputStream</span> with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt"><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> to call webservice and return response as InputStream
This is implemented as FileRefDataObject because the response is treated as some file content.</p><div class="fullcomment"><div class="comment cmt"><p><a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a> to call webservice and return response as InputStream
This is implemented as FileRefDataObject because the response is treated as some file content.
FileRefDataObjects support partitioned data. For a WebserviceFileDataObject partitions are mapped as query parameters to create query string.
All possible query parameter values must be given in configuration.</p></div><dl class="paramcmts block"><dt class="param">partitionDefs</dt><dd class="cmt"><p>list of partitions with list of possible values for every entry</p></dd><dt class="param">partitionLayout</dt><dd class="cmt"><p>definition of partitions in query string. Use %&lt;partitionColName&gt;% as placeholder for partition column value in layout.</p></dd></dl></div>
    </li><li name="io.smartdatalake.workflow.dataobject.WebservicePartitionDefinition" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="WebservicePartitionDefinitionextendsProductwithSerializable"></a><a id="WebservicePartitionDefinition:WebservicePartitionDefinition"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/WebservicePartitionDefinition.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="" href="WebservicePartitionDefinition.html"><span class="name">WebservicePartitionDefinition</span></a><span class="params">(<span name="name">name: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="values">values: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.XmlFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="XmlFileDataObjectextendsSparkFileDataObjectwithCanCreateDataFramewithCanWriteDataFramewithProductwithSerializable"></a><a id="XmlFileDataObject:XmlFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/XmlFileDataObject.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A io.smartdatalake.workflow.dataobject.DataObject backed by an XML data source." href="XmlFileDataObject.html"><span class="name">XmlFileDataObject</span></a><span class="params">(<span name="id">id: <a href="../../config/SdlConfigObject$$DataObjectId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.DataObjectId">DataObjectId</a></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="rowTag">rowTag: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="xmlOptions">xmlOptions: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="partitions">partitions: <a href="../../../../scala/index.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">Seq()</a></span></span></span>, <span name="schema">schema: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="schemaMin">schemaMin: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="saveMode">saveMode: <a href="../../definitions/SDLSaveMode$.html#SDLSaveMode=io.smartdatalake.definitions.SDLSaveMode.Value" class="extmbr" name="io.smartdatalake.definitions.SDLSaveMode.SDLSaveMode">SDLSaveMode</a> = <span class="symbol"><span class="name"><a href="../../../index.html">SDLSaveMode.Overwrite</a></span></span></span>, <span name="sparkRepartition">sparkRepartition: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/hdfs/SparkRepartitionDef.html" class="extype" name="io.smartdatalake.util.hdfs.SparkRepartitionDef">SparkRepartitionDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="flatten">flatten: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>, <span name="acl">acl: <span class="extype" name="scala.Option">Option</span>[<a href="../../util/misc/AclDef.html" class="extype" name="io.smartdatalake.util.misc.AclDef">AclDef</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="connectionId">connectionId: <span class="extype" name="scala.Option">Option</span>[<a href="../../config/SdlConfigObject$$ConnectionId.html" class="extype" name="io.smartdatalake.config.SdlConfigObject.ConnectionId">ConnectionId</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="filenameColumn">filenameColumn: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="expectedPartitionsCondition">expectedPartitionsCondition: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>, <span name="metadata">metadata: <span class="extype" name="scala.Option">Option</span>[<a href="DataObjectMetadata.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectMetadata">DataObjectMetadata</a>] = <span class="symbol"><span class="name"><a href="../../../../scala/index.html">None</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="instanceRegistry">instanceRegistry: <span class="extype" name="io.smartdatalake.config.InstanceRegistry">InstanceRegistry</span></span>)</span><span class="result"> extends <span class="extype" name="io.smartdatalake.workflow.dataobject.SparkFileDataObject">SparkFileDataObject</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanCreateDataFrame">CanCreateDataFrame</span> with <span class="extype" name="io.smartdatalake.workflow.dataobject.CanWriteDataFrame">CanWriteDataFrame</span> with <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an XML data source.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">io.smartdatalake.workflow.dataobject.DataObject</a> backed by an XML data source.</p><p>It manages read and write access and configurations required for <span class="extype" name="io.smartdatalake.workflow.action.Action">io.smartdatalake.workflow.action.Action</span>s to
work on XML formatted files.</p><p>Reading and writing details are delegated to Apache Spark <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span>
and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span> respectively. The reader and writer implementations are provided by
the <a href="https://github.com/databricks/spark-xml" target="_blank">databricks spark-xml</a> proect.
</p></div><dl class="paramcmts block"><dt class="param">xmlOptions</dt><dd class="cmt"><p>Settings for the underlying <span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span> and <span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span>.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>An optional data object schema. If defined, any automatic schema inference is avoided. As this corresponds to the schema on write, it must not include the optional filenameColumn on read.</p></dd><dt class="param">sparkRepartition</dt><dd class="cmt"><p>Optional definition of repartition operation before writing DataFrame with Spark to Hadoop.</p></dd><dt class="param">expectedPartitionsCondition</dt><dd class="cmt"><p>Optional definition of partitions expected to exist.
                                   Define a Spark SQL expression that is evaluated against a <span class="extype" name="PartitionValues">PartitionValues</span> instance and returns true or false
                                   Default is to expect all partitions to exist.</p></dd></dl><dl class="attributes block"> <dt>See also</dt><dd><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameReader">org.apache.spark.sql.DataFrameReader</span></p></span><span class="cmt"><p><span class="extype" name="org.apache.spark.sql.DataFrameWriter">org.apache.spark.sql.DataFrameWriter</span></p></span></dd></dl></div>
    </li></ol>
            </div>

        

        <div class="values members">
              <h3>Value Members</h3>
              <ol>
                <li name="io.smartdatalake.workflow.dataobject.AccessTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="AccessTableDataObject"></a><a id="AccessTableDataObject:AccessTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/AccessTableDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="AccessTableDataObject$.html"><span class="name">AccessTableDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.ActionsExporterDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="ActionsExporterDataObject"></a><a id="ActionsExporterDataObject:ActionsExporterDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ActionsExporterDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="ActionsExporterDataObject$.html"><span class="name">ActionsExporterDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="ActionsExporterDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.ActionsExporterDataObject">ActionsExporterDataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.AvroFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="AvroFileDataObject"></a><a id="AvroFileDataObject:AvroFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/AvroFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="AvroFileDataObject$.html"><span class="name">AvroFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.CsvFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="CsvFileDataObject"></a><a id="CsvFileDataObject:CsvFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CsvFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="CsvFileDataObject$.html"><span class="name">CsvFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.CustomDfDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="CustomDfDataObject"></a><a id="CustomDfDataObject:CustomDfDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CustomDfDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="CustomDfDataObject$.html"><span class="name">CustomDfDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.CustomFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="CustomFileDataObject"></a><a id="CustomFileDataObject:CustomFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/CustomFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="CustomFileDataObject$.html"><span class="name">CustomFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.DataObjectsExporterDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="DataObjectsExporterDataObject"></a><a id="DataObjectsExporterDataObject:DataObjectsExporterDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/DataObjectsExporterDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="DataObjectsExporterDataObject$.html"><span class="name">DataObjectsExporterDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObjectsExporterDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObjectsExporterDataObject">DataObjectsExporterDataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.ExcelFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="ExcelFileDataObject"></a><a id="ExcelFileDataObject:ExcelFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ExcelFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="ExcelFileDataObject$.html"><span class="name">ExcelFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.HiveTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="HiveTableDataObject"></a><a id="HiveTableDataObject:HiveTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/HiveTableDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="HiveTableDataObject$.html"><span class="name">HiveTableDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.JdbcTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="JdbcTableDataObject"></a><a id="JdbcTableDataObject:JdbcTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/JdbcTableDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="JdbcTableDataObject$.html"><span class="name">JdbcTableDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.JsonFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="JsonFileDataObject"></a><a id="JsonFileDataObject:JsonFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/JsonFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="JsonFileDataObject$.html"><span class="name">JsonFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.PKViolatorsDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="PKViolatorsDataObject"></a><a id="PKViolatorsDataObject:PKViolatorsDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/PKViolatorsDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="PKViolatorsDataObject$.html"><span class="name">PKViolatorsDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="PKViolatorsDataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.PKViolatorsDataObject">PKViolatorsDataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.ParquetFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="ParquetFileDataObject"></a><a id="ParquetFileDataObject:ParquetFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/ParquetFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="ParquetFileDataObject$.html"><span class="name">ParquetFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.RawFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="RawFileDataObject"></a><a id="RawFileDataObject:RawFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/RawFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="RawFileDataObject$.html"><span class="name">RawFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.SFtpFileRefDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="SFtpFileRefDataObject"></a><a id="SFtpFileRefDataObject:SFtpFileRefDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/SFtpFileRefDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="SFtpFileRefDataObject$.html"><span class="name">SFtpFileRefDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.TickTockHiveTableDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="TickTockHiveTableDataObject"></a><a id="TickTockHiveTableDataObject:TickTockHiveTableDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/TickTockHiveTableDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="TickTockHiveTableDataObject$.html"><span class="name">TickTockHiveTableDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.WebserviceFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="WebserviceFileDataObject"></a><a id="WebserviceFileDataObject:WebserviceFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/WebserviceFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="WebserviceFileDataObject$.html"><span class="name">WebserviceFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="io.smartdatalake.util.misc.SmartDataLakeLogger">SmartDataLakeLogger</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="io.smartdatalake.workflow.dataobject.XmlFileDataObject" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="XmlFileDataObject"></a><a id="XmlFileDataObject:XmlFileDataObject"></a>
      <span class="permalink">
      <a href="../../../../io/smartdatalake/workflow/dataobject/XmlFileDataObject$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="XmlFileDataObject$.html"><span class="name">XmlFileDataObject</span></a><span class="result"> extends <span class="extype" name="io.smartdatalake.config.FromConfigFactory">FromConfigFactory</span>[<a href="DataObject.html" class="extype" name="io.smartdatalake.workflow.dataobject.DataObject">DataObject</a>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li>
              </ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
    </body>
          </div>
        </div>
      </div>
    </body>
      </html>
