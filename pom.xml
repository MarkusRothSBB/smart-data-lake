<!--
  ~ Smart Data Lake - Build your data lake the smart way.
  ~
  ~ Copyright Â© 2019-2020 ELCA Informatique SA (<https://www.elca.ch>)
  ~
  ~ This program is free software: you can redistribute it and/or modify
  ~ it under the terms of the GNU General Public License as published by
  ~ the Free Software Foundation, either version 3 of the License, or
  ~ (at your option) any later version.
  ~
  ~ This program is distributed in the hope that it will be useful,
  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ~ GNU General Public License for more details.
  ~
  ~ You should have received a copy of the GNU General Public License
  ~ along with this program. If not, see <http://www.gnu.org/licenses/>.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>io.smartdatalake</groupId>
	<artifactId>smartdatalake_${scala.minor.version}</artifactId>
	<version>1.0.0</version>
	<packaging>jar</packaging>

	<licenses>
		<license>
			<name>GNU General Public License (GPL) version 3</name>
			<url>https://www.gnu.org/licenses/gpl-3.0.html</url>
		</license>
	</licenses>

	<!-- Used for license header by maven-license-plugin -->
	<name>Smart Data Lake</name>
	<description>Build your data lake the smart way.</description>
	<inceptionYear>2019</inceptionYear>
	<organization>
		<name>ELCA Informatique SA</name>
		<url>https://www.elca.ch</url>
	</organization>

	<profiles>
		<profile>
			<id>fat-jar</id>
			<properties>
				<skip.assembly>false</skip.assembly>
			</properties>
		</profile>
		<profile>
			<!-- do not use this profile if you want to see warnings about missing links
            it makes sense to check warnings about internal (public) members, but we will always have
            warnings for external libraries which is why we deactivate them -->
			<id>scala-doc-nolinkwarnings</id>
			<properties>
				<noLinkWarnings>-no-link-warnings</noLinkWarnings>
			</properties>
		</profile>
		<profile>
			<id>scala-2.12</id>
			<properties>
				<scala.minor.version>2.12</scala.minor.version>
				<scala.version>${scala.minor.version}.10</scala.version>
			</properties>
		</profile>
		<profile>
			<id>scala-2.11</id>
			<activation><activeByDefault>true</activeByDefault></activation>
			<properties>
				<scala.minor.version>2.11</scala.minor.version>
				<scala.version>${scala.minor.version}.12</scala.version>
			</properties>
		</profile>
	</profiles>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<skip.assembly>true</skip.assembly>
		<noLinkWarnings>-unchecked</noLinkWarnings>

		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<maven.compiler.release>8</maven.compiler.release>

		<slf4j.version>1.7.30</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<scopt.version>3.7.1</scopt.version>

		<!-- hadoop version must match the hadoop version included by spark-core -->
		<hadoop.version>2.6.5</hadoop.version>
		<spark.version>2.4.4</spark.version>

		<databricks.spark-xml.version>0.9.0</databricks.spark-xml.version>

		<spark.excel.version>0.12.0</spark.excel.version>
		<ucanaccess.version>4.0.4</ucanaccess.version>
		<!-- when changing config version, remember to update it in DatabricksSmartDataLakeBuilder main method -->
		<typesafe.config.version>1.3.4</typesafe.config.version>
		<scala-arm.version>2.0</scala-arm.version>
		<scalatest.version>3.0.1</scalatest.version>
		<splunk.version>1.6.5.0</splunk.version>
		<sshj.version>0.21.1</sshj.version>

		<keycloak.version>4.5.0.Final</keycloak.version>
		<license-maven-plugin.version>3.0</license-maven-plugin.version>

		<deltaTable.version>0.5.0</deltaTable.version>
	</properties>

	<distributionManagement>
		<repository>
			<id>bintray-smart-data-lake-smart-data-lake</id>
			<name>smart-data-lake-smart-data-lake</name>
			<url>https://api.bintray.com/maven/smart-data-lake/smart-data-lake/smart-data-lake/;publish=1</url>
		</repository>
	</distributionManagement>

	<scm>
		<connection>scm:git:git://github.com/smart-data-lake/smart-data-lake.git</connection>
		<developerConnection>scm:git:ssh://github.com/smart-data-lake/smart-data-lake.git</developerConnection>
		<url>http://github.com/smart-data-lake/smart-data-lake/tree/master</url>
	</scm>

	<repositories>
		<repository>
			<id>spring-plugins</id>
			<name>Spring Plugins Repository</name>
			<url>https://repo.spring.io/plugins-release/</url>
		</repository>
	</repositories>

	<build>
		<!-- for creating scala docs for workflow objects only, temporarily replace the line below with: <sourceDirectory>src/main/scala/io/smartdatalake/workflow</sourceDirectory> -->
		<sourceDirectory>src/main/scala</sourceDirectory>
		<testSourceDirectory>src/test/scala</testSourceDirectory>
		<resources>
			<resource>
				<directory>src/main/resources</directory>
			</resource>
			<resource>
				<targetPath>META-INF</targetPath>
				<directory>${basedir}</directory>
				<filtering>false</filtering>
				<includes>
					<include>COPYING</include> <!-- the file containing the license text -->
				</includes>
			</resource>
		</resources>
		<testResources>
			<testResource>
				<directory>src/test/resources</directory>
			</testResource>
		</testResources>

		<plugins>
			<!-- Compiles Scala sources. -->
			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>4.3.1</version>
				<executions>
					<execution>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<scalaCompatVersion>${scala.minor.version}</scalaCompatVersion>
					<checkMultipleScalaVersions>true</checkMultipleScalaVersions>
					<failOnMultipleScalaVersions>true</failOnMultipleScalaVersions>
					<recompileMode>incremental</recompileMode>
					<args>
						<arg>-unchecked</arg>
						<arg>-deprecation</arg>
						<arg>-feature</arg>
						<arg>-explaintypes</arg>
						<arg>-target:jvm-1.8</arg>
						<arg>${noLinkWarnings}</arg>
					</args>
					<jvmArgs>
						<jvmArg>-Xms64m</jvmArg>
						<jvmArg>-Xmx1024m</jvmArg>
					</jvmArgs>
				</configuration>
			</plugin>

			<!-- rewrite pom for compiling with different scala version profiles -->
			<plugin>
				<groupId>org.spurint.maven.plugins</groupId>
				<artifactId>scala-cross-maven-plugin</artifactId>
				<version>0.2.1</version>
				<executions>
					<execution>
						<id>rewrite-pom</id>
						<goals>
							<goal>rewrite-pom</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Copies files in resources folders to target folder. -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-resources-plugin</artifactId>
				<version>3.1.0</version>
			</plugin>

			<!-- Checks whether source files have the specified license header. -->
			<plugin>
				<groupId>com.mycila</groupId>
				<artifactId>license-maven-plugin</artifactId>
				<version>${license-maven-plugin.version}</version>
				<configuration>
					<header>src/license/gplv3-header.txt</header>
					<properties>
						<copyright.name>${project.organization.name}</copyright.name>
						<copyright.contact>${project.organization.url}</copyright.contact>
					</properties>
					<includes>
						<include>src/**</include>
					</includes>
					<excludes>
						<exclude>**/*.accdb</exclude>
						<exclude>**/*.mdb</exclude>
						<exclude>**/*.csv</exclude>
						<exclude>**/*.keytab</exclude>
						<exclude>**/*.pkcs12</exclude>
					</excludes>
					<mapping>
						<scala>SLASHSTAR_STYLE</scala>
						<conf>SCRIPT_STYLE</conf>
					</mapping>
					<failIfMissing>false</failIfMissing>
				</configuration>
				<dependencies>
					<dependency>
						<groupId>com.mycila</groupId>
						<artifactId>license-maven-plugin-git</artifactId>
						<version>${license-maven-plugin.version}</version>
					</dependency>
				</dependencies>
				<executions>
					<execution>
						<!--<phase>process-sources</phase>-->
						<goals>
							<goal>check</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Creates the jar without dependencies -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<version>3.1.2</version>
				<configuration>
					<archive>
						<manifest>
							<addClasspath>true</addClasspath>
							<mainClass>io.smartdatalake.app.DefaultSmartDataLakeBuilder</mainClass>
						</manifest>
						<manifestEntries>
							<Implementation-Version>${project.version}</Implementation-Version>
						</manifestEntries>
					</archive>
					<excludes>
						<exclude>log4j.properties</exclude> <!-- Logging configuration should be left to user. -->
					</excludes>
				</configuration>
			</plugin>

			<!-- Creates a JAR file with the source files of the project. -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-source-plugin</artifactId>
				<version>3.1.0</version>
				<executions>
					<execution>
						<id>attach-sources</id>
						<goals>
							<goal>jar-no-fork</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<excludes>
						<exclude>log4j.properties</exclude> <!-- Logging configuration source should not be distributed. -->
					</excludes>
				</configuration>
			</plugin>

			<!-- Builds executable jar that includes all runtime dependencies -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-assembly-plugin</artifactId>
				<version>3.1.1</version>
				<configuration>
					<descriptorRefs>
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
					<archive>
						<manifest>
							<mainClass>io.smartdatalake.app.DefaultSmartDataLakeBuilder</mainClass>
						</manifest>
						<manifestEntries>
							<Implementation-Version>${project.version}</Implementation-Version>
						</manifestEntries>
					</archive>
					<skipAssembly>${skip.assembly}</skipAssembly>
				</configuration>
				<executions>
					<execution>
						<id>make-assembly</id>
						<phase>package</phase>
						<goals>
							<goal>single</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Executes units tests with scalatest  -->
			<plugin>
				<groupId>org.scalatest</groupId>
				<artifactId>scalatest-maven-plugin</artifactId>
				<version>2.0.0</version>
				<configuration>
					<reportsDirectory>
						${project.build.directory}/scalatest-reports
					</reportsDirectory>
					<junitxml>.</junitxml>
					<filereports>
						${project.artifactId}.txt
					</filereports>
					<stdout>WT</stdout>  <!-- without color, show reminder of failed and canceled tests with short stack traces, see: http://www.scalatest.org/user_guide/using_scalatest_with_sbt-->
					<environmentVariables>
						<SPARK_LOCAL_IP>127.0.0.1</SPARK_LOCAL_IP> <!-- Suppresses Spark IP discovery during tests (when executed with mvn test) -->
					</environmentVariables>
				</configuration>
				<executions>
					<execution>
						<goals>
							<goal>test</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Allows handling of version numbers -->
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>versions-maven-plugin</artifactId>
				<version>2.7</version>
			</plugin>

			<!-- Checks for declared but unused and undeclared but used dependencies in the verify stage -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-dependency-plugin</artifactId>
				<version>3.1.1</version>
				<configuration>
					<failOnWarning>false</failOnWarning>
					<ignoreNonCompile>true</ignoreNonCompile>
					<ignoredUsedUndeclaredDependencies>
						<dependency>org.scalacheck:scalacheck_${scala.minor.version}</dependency>
					</ignoredUsedUndeclaredDependencies>
				</configuration>
				<executions>
					<execution>
						<goals>
							<goal>analyze-only</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

		</plugins>

	</build>

	<dependencies>
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-api</artifactId>
			<version>${slf4j.version}</version>
		</dependency>
		<dependency>
			<groupId>com.databricks</groupId>
			<artifactId>dbutils-api_2.11</artifactId>
			<version>0.0.4</version>
		</dependency>
		<!-- Log4j is used in some unit tests to disable some exception logging -->
		<dependency>
			<groupId>log4j</groupId>
			<artifactId>log4j</artifactId>
			<version>${log4j.version}</version>
		</dependency>
		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.minor.version}</artifactId>
			<version>${scopt.version}</version>
		</dependency>

		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>${hadoop.version}</version>
			<exclusions>
				<!-- spark ui api uses a newer version of jersey and javax.servlet, we need to exclude it here! -->
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-json</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-server</artifactId>
				</exclusion>
				<exclusion>
					<groupId>javax.servlet</groupId>
					<artifactId>servlet-api</artifactId>
				</exclusion>			</exclusions>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-catalyst_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>

		<dependency>
			<groupId>com.databricks</groupId>
			<artifactId>spark-xml_${scala.minor.version}</artifactId>
			<version>${databricks.spark-xml.version}</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-avro_${scala.minor.version}</artifactId>
			<version>${spark.version}</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>commons-io</groupId>
			<artifactId>commons-io</artifactId>
			<version>2.4</version>
		</dependency>
		<dependency>
			<groupId>com.healthmarketscience.jackcess</groupId>
			<artifactId>jackcess</artifactId>
			<version>2.1.11</version>
		</dependency>
		<dependency>
			<groupId>org.apache.avro</groupId>
			<artifactId>avro</artifactId>
			<version>1.8.2</version>
		</dependency>
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-lang3</artifactId>
			<version>3.5</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>com.crealytics</groupId>
			<artifactId>spark-excel_${scala.minor.version}</artifactId>
			<version>${spark.excel.version}</version>
			<scope>runtime</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.poi</groupId>
			<artifactId>poi</artifactId>
			<version>4.0.0</version>
			<scope>runtime</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.poi</groupId>
			<artifactId>poi-ooxml</artifactId>
			<version>4.0.0</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>net.sf.ucanaccess</groupId>
			<artifactId>ucanaccess</artifactId>
			<version>${ucanaccess.version}</version>
			<scope>runtime</scope>
		</dependency>

		<dependency>
			<groupId>com.hierynomus</groupId>
			<artifactId>sshj</artifactId>
			<version>${sshj.version}</version>
		</dependency>

		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-reflect</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-compiler</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang.modules</groupId>
			<artifactId>scala-xml_${scala.minor.version}</artifactId>
			<version>1.0.5</version>
		</dependency>

		<dependency>
			<groupId>com.typesafe</groupId>
			<artifactId>config</artifactId>
			<version>${typesafe.config.version}</version>
		</dependency>

		<dependency>
			<groupId>com.jsuereth</groupId>
			<artifactId>scala-arm_${scala.minor.version}</artifactId>
			<version>${scala-arm.version}</version>
		</dependency>

		<dependency>
			<groupId>org.scalatest</groupId>
			<artifactId>scalatest_${scala.minor.version}</artifactId>
			<version>${scalatest.version}</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.scalactic</groupId>
			<artifactId>scalactic_${scala.minor.version}</artifactId>
			<version>${scalatest.version}</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.scalacheck</groupId>
			<artifactId>scalacheck_${scala.minor.version}</artifactId>
			<version>1.14.3</version>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.sshd</groupId>
			<artifactId>sshd-sftp</artifactId>
			<version>2.3.0</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.sshd</groupId>
			<artifactId>sshd-common</artifactId>
			<version>2.3.0</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.sshd</groupId>
			<artifactId>sshd-core</artifactId>
			<version>2.3.0</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>com.github.tomakehurst</groupId>
			<artifactId>wiremock-standalone</artifactId>
			<version>2.25.1</version>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>net.i2p.crypto</groupId>
			<artifactId>eddsa</artifactId>
			<version>0.3.0</version>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>com.splunk</groupId>
			<artifactId>splunk</artifactId>
			<version>${splunk.version}</version>
		</dependency>

		<dependency>
			<groupId>org.scalaj</groupId>
			<artifactId>scalaj-http_${scala.minor.version}</artifactId>
			<version>2.3.0</version>
		</dependency>

		<dependency>
			<groupId>javax.jms</groupId>
			<artifactId>jms</artifactId>
			<version>1.1</version>
		</dependency>

		<!-- Start Keycloak dependencies -->
		<dependency>
			<groupId>org.keycloak</groupId>
			<artifactId>keycloak-core</artifactId>
			<version>${keycloak.version}</version>
		</dependency>
		<dependency>
			<groupId>org.keycloak</groupId>
			<artifactId>keycloak-admin-client</artifactId>
			<version>${keycloak.version}</version>
		</dependency>

		<!--  only used for keycloak admin api -->
		<dependency>
			<groupId>org.jboss.resteasy</groupId>
			<artifactId>resteasy-client</artifactId>
			<version>3.1.3.Final</version>
			<scope>runtime</scope>
		</dependency>
		<!-- End Keycloak dependencies -->

		<dependency>
			<groupId>com.github.kxbmap</groupId>
			<artifactId>configs_${scala.minor.version}</artifactId>
			<version>0.4.4</version>
		</dependency>

		<dependency>
			<groupId>io.monix</groupId>
			<artifactId>monix-eval_${scala.minor.version}</artifactId>
			<version>3.1.0</version>
		</dependency>
		<dependency>
			<groupId>io.monix</groupId>
			<artifactId>monix-execution_${scala.minor.version}</artifactId>
			<version>3.1.0</version>
		</dependency>

		<dependency>
			<groupId>com.github.mutcianm</groupId>
			<artifactId>ascii-graphs_${scala.minor.version}</artifactId>
			<version>0.0.6</version>
		</dependency>

		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-pool2</artifactId>
			<version>2.8.0</version>
		</dependency>
		<dependency>
			<groupId>joda-time</groupId>
			<artifactId>joda-time</artifactId>
			<version>2.9.3</version>
		</dependency>

		<dependency>
			<groupId>io.delta</groupId>
			<artifactId>delta-core_${scala.minor.version}</artifactId>
			<version>${deltaTable.version}</version>
		</dependency>

	</dependencies>
</project>